% Experiments Chapter (English)
% Chapter - Experiments on Physics-Guided Synthetic Data Generation for WiFi CSI HAR

\chapter{Experiments on Physics-Guided Synthetic Data Generation for WiFi CSI HAR}
\label{chap:experiments}

\section{姒傝堪}
\label{sec:overview}

鏈珷璇︾粏鎻忚堪浜嗗熀浜庣墿鐞嗘寚瀵肩殑鍚堟垚鏁版嵁鐢熸垚妗嗘灦鍦╓iFi CSI浜轰綋娲诲姩璇嗗埆浠诲姟涓殑瀹屾暣瀹為獙鐮旂┒銆傚疄楠屽伐浣滃巻鏃舵暟鏈堬紝鍖呭惈浜嗕粠鐞嗚璁捐銆佺畻娉曞疄鐜般€佺郴缁熷紑鍙戝埌鍏ㄩ潰璇勪及鐨勫畬鏁寸爺绌舵祦绋嬨€?

\subsection{鐮旂┒鑳屾櫙涓庡姩鏈簘
\label{subsec:motivation}

WiFi CSI锛圕hannel State Information锛夊熀浜庣殑浜轰綋娲诲姩璇嗗埆鎶€鏈綔涓轰竴绉嶆柊鍏寸殑鏅€傛劅鐭ユ柟娉曪紝鍏锋湁闅愮淇濇姢銆佽澶囨棤鍏炽€侀儴缃蹭究鎹风瓑鏄捐憲浼樺娍銆傜劧鑰岋紝鐜版湁鐮旂┒闈复鐨勬牳蹇冩寫鎴樺寘鎷細

\begin{enumerate}
\item \textbf{鏁版嵁绋€缂烘€锛氭爣娉ㄧ湡瀹炰笘鐣學iFi CSI鏁版嵁闇€瑕佸ぇ閲忎汉鍔涚墿鍔涳紝鎴愭湰楂樻槀
\item \textbf{璺ㄥ煙娉涘寲鍥伴毦}锛氭ā鍨嬪湪涓嶅悓鐜銆佷笉鍚屽彈璇曡€呬箣闂寸殑娉涘寲鑳藉姏鏈夐檺  
\item \textbf{璇勪及鏂规硶涓嶅畬鍠剗锛氱己涔忕郴缁熸€х殑鍙俊搴﹁瘎浼板拰鏍″噯鍒嗘瀽
\item \textbf{鏍囩鏁堢巼浣庝笅}锛氫紶缁熺洃鐫ｅ涔犻渶瑕佸ぇ閲忔爣娉ㄦ暟鎹紝瀹為檯閮ㄧ讲鎴愭湰杩囬珮
\end{enumerate}

\subsection{鐮旂┒鐩爣涓庤础鐚畗
\label{subsec:objectives}

閽堝涓婅堪鎸戞垬锛屾湰鐮旂┒鐨勬牳蹇冪洰鏍囨槸寮€鍙戜竴濂楀畬鏁寸殑鐗╃悊鎸囧鍚堟垚鏁版嵁鐢熸垚涓庡彲淇¤瘎浼版鏋讹紝鍏蜂綋鍖呮嫭锛?

\begin{itemize}
\item 寤虹珛鍩轰簬WiFi淇″彿浼犳挱鐗╃悊鍘熺悊鐨勫悎鎴愭暟鎹敓鎴愬櫒
\item 璁捐Enhanced娣卞害瀛︿範鏋舵瀯锛岄泦鎴怱E娉ㄦ剰鍔涙満鍒跺拰鏃跺簭寤烘ā
\item 鏋勫缓绯荤粺鎬х殑璺ㄥ煙璇勪及鍗忚锛圕DAE鍜孲TEA锛?
\item 瀹炵幇楂樻晥鐨凷im2Real杩佺Щ瀛︿範锛屽ぇ骞呴檷浣庢爣娉ㄩ渶姹?
\item 寤虹珛鍙俊搴﹁瘎浼颁綋绯伙紝鍖呮嫭鏍″噯鍒嗘瀽鍜屽彲闈犳€ф祴璇?
\end{itemize}

\section{瀹為獙璁捐涓庢柟娉曡}
\label{sec:methodology}

\subsection{鎬讳綋瀹為獙妗嗘灦}
\label{subsec:framework}

鏈爺绌堕噰鐢ㄤ笁闃舵閫掕繘寮忓疄楠岃璁★細

\begin{description}
\item[绗竴闃舵] \textbf{鍚堟垚鏁版嵁楠岃瘉瀹為獙锛圖2鍗忚锛墋锛氶€氳繃540绉嶉厤缃獙璇佸悎鎴愭暟鎹敓鎴愬櫒鐨勬湁鏁堟€у拰椴佹鎬?
\item[绗簩闃舵] \textbf{璺ㄥ煙閫傚簲璇勪及瀹為獙锛圕DAE鍗忚锛墋锛氶€氳繃40绉嶉厤缃獙璇佹ā鍨嬬殑璺ㄥ彈璇曡€呭拰璺ㄧ幆澧冩硾鍖栬兘鍔?
\item[绗笁闃舵] \textbf{Sim2Real杩佺Щ鏁堢巼璇勪及瀹為獙锛圫TEA鍗忚锛墋锛氶€氳繃56绉嶉厤缃噺鍖栧悎鎴愬埌鐪熷疄鏁版嵁鐨勮縼绉诲涔犳晥鐜?
\end{description}

\subsection{鐗╃悊鎸囧鐨勫悎鎴愭暟鎹敓鎴愬師鐞唥
\label{subsec:physics_principles}

\subsubsection{WiFi淇″彿浼犳挱寤烘ā}
WiFi CSI淇″彿鐨勭敓鎴愬熀浜庣粡鍏哥殑鏃犵嚎淇￠亾浼犳挱鐞嗚銆傝CSI鐭╅樀涓?\mathbf{H} \in \mathbb{C}^{N_t \times N_r \times K}$锛屽叾涓?N_t$鍜?N_r$鍒嗗埆涓哄彂灏勫拰鎺ユ敹澶╃嚎鏁伴噺锛?K$涓哄瓙杞芥尝鏁伴噺銆?

淇￠亾鍝嶅簲寤烘ā涓猴細
\begin{equation}
\mathbf{H}(f_k) = \sum_{l=1}^{L} \alpha_l e^{-j2\pi f_k \tau_l} \mathbf{a}_r(\theta_{r,l}) \mathbf{a}_t^H(\theta_{t,l})
\label{eq:channel_model}
\end{equation}

鍏朵腑锛?
\begin{itemize}
\item $\alpha_l$锛氱$l$鏉¤矾寰勭殑澶嶅鐩?
\item $\tau_l$锛氱$l$鏉¤矾寰勭殑鏃跺欢
\item $\theta_{r,l}, \theta_{t,l}$锛氭帴鏀跺拰鍙戝皠瑙掑害
\item $\mathbf{a}_r(\cdot), \mathbf{a}_t(\cdot)$锛氬ぉ绾块樀鍒楀搷搴斿悜閲?
\end{itemize}

\subsubsection{浜轰綋浜や簰寤烘ā}
浜轰綋娲诲姩瀵筗iFi淇″彿鐨勫奖鍝嶉€氳繃鍔ㄦ€佹暎灏勪綋寤烘ā锛?

\begin{equation}
\alpha_l(t) = \alpha_{l,0} + \Delta\alpha_l(t) \cdot f_{\text{activity}}(t)
\label{eq:human_interaction}
\end{equation}

鍏朵腑$f_{\text{activity}}(t)$涓烘椿鍔ㄧ壒寰佸嚱鏁帮紝閽堝涓嶅悓娲诲姩绫诲瀷锛堝潗绔嬨€佺珯绔嬨€佽璧般€佽穼鍊掞級鍏锋湁涓嶅悓鐨勬椂棰戠壒寰併€?

\subsection{Enhanced妯″瀷鏋舵瀯璁捐}
\label{subsec:enhanced_architecture}

\subsubsection{鏁翠綋鏋舵瀯}
Enhanced妯″瀷閲囩敤鍒嗗眰鐗瑰緛鎻愬彇绛栫暐锛屽寘鍚互涓嬪叧閿粍浠讹細

\begin{enumerate}
\item \textbf{鍗风Н鐗瑰緛鎻愬彇灞倉锛氬灞?D鍗风Н鎻愬彇鏃堕鐗瑰緛
\item \textbf{SE娉ㄦ剰鍔涙ā鍧梷锛氶€氶亾绾ц嚜閫傚簲鐗瑰緛閲嶅姞鏉?
\item \textbf{鏃跺簭寤烘ā灞倉锛欱iLSTM鎹曡幏闀跨▼鏃跺簭渚濊禆
\item \textbf{鏃跺簭娉ㄦ剰鍔涙満鍒秨锛歈uery-Key-Value缁撴瀯寤烘ā鍏ㄥ眬渚濊禆
\item \textbf{鍒嗙被杈撳嚭灞倉锛氬叏杩炴帴灞傝緭鍑哄洓绫绘椿鍔ㄦ鐜?
\end{enumerate}

妯″瀷鐨勬暟瀛﹁〃绀轰负锛?
\begin{align}
\mathbf{X}_{\text{conv}} &= \text{Conv1D}(\mathbf{X}_{\text{input}}) \\
\mathbf{X}_{\text{se}} &= \text{SE}(\mathbf{X}_{\text{conv}}) \\
\mathbf{X}_{\text{lstm}} &= \text{BiLSTM}(\mathbf{X}_{\text{se}}) \\
\mathbf{X}_{\text{attn}} &= \text{Attention}(\mathbf{X}_{\text{lstm}}) \\
\mathbf{y} &= \text{Classifier}(\mathbf{X}_{\text{attn}})
\end{align}

\subsubsection{SE娉ㄦ剰鍔涙満鍒秨
SE妯″潡鐨勫疄鐜伴噰鐢ㄥ叏灞€骞冲潎姹犲寲鍜屼袱灞傚叏杩炴帴缃戠粶锛?

\begin{align}
\mathbf{z} &= \text{GAP}(\mathbf{X}) = \frac{1}{T}\sum_{t=1}^{T}\mathbf{X}_t \\
\mathbf{s} &= \sigma(\mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 \mathbf{z})) \\
\tilde{\mathbf{X}} &= \mathbf{s} \odot \mathbf{X}
\end{align}

鍏朵腑$\mathbf{W}_1 \in \mathbb{R}^{C/r \times C}$鍜?\mathbf{W}_2 \in \mathbb{R}^{C \times C/r}$涓哄彲瀛︿範鍙傛暟锛?r$涓洪檷缁存瘮渚嬨€?

\section{瀹為獙鍗忚涓庤瘎浼版柟娉晑
\label{sec:protocols}

\subsection{D2鍗忚锛氬悎鎴愭暟鎹瞾妫掓€ч獙璇亇
\label{subsec:d2_protocol}

D2鍗忚鏃ㄥ湪楠岃瘉鍚堟垚鏁版嵁鐢熸垚鍣ㄧ殑椴佹鎬у拰鍙帶鎬э紝閫氳繃绯荤粺鎬у湴鍙樺寲鍏抽敭鐗╃悊鍙傛暟鏉ユ祴璇曟ā鍨嬫€ц兘銆?

\subsubsection{瀹為獙璁捐}
\begin{itemize}
\item \textbf{閰嶇疆鎬绘暟}锛?40绉嶉厤缃?
\item \textbf{鍙樺寲鍙傛暟}锛氬櫔澹版按骞炽€佺被鍒噸鍙犲害銆佷俊閬撹“钀姐€佽皭娉㈠共鎵?
\item \textbf{闅惧害绛夌骇}锛氫綆銆佷腑銆侀珮涓変釜绛夌骇
\item \textbf{闅忔満绉嶅瓙}锛氭瘡绉嶉厤缃?涓嫭绔嬮殢鏈虹瀛?
\item \textbf{妯″瀷瀵规瘮}锛欵nhanced vs CNN vs BiLSTM vs Conformer-lite
\end{itemize}

\subsubsection{鍏抽敭鍙傛暟璁剧疆}
\begin{table}[h]
\centering
\caption{D2鍗忚鍏抽敭鍙傛暟閰嶇疆}
\label{tab:d2_parameters}
\begin{tabular}{@{}lll@{}}
\toprule
鍙傛暟绫诲埆 & 鍙傛暟鍚嶇О & 鍙栧€艰寖鍥?\\
\midrule
鏁版嵁瑙勬ā & 鏍锋湰鏁伴噺 & 20,000 \\
& 鏃堕棿闀垮害 & 128 \\
& 棰戠巼缁村害 & 52 \\
\midrule
璁粌鍙傛暟 & 鎵规澶у皬 & 768 \\
& 瀛︿範鐜?& $10^{-3}$ \\
& 浼樺寲鍣?& Adam \\
& 瀛︿範鐜囪皟搴?& Cosine琛板噺 \\
\midrule
闅惧害鎺у埗 & 绫诲埆閲嶅彔搴?& 0.3-0.8 \\
& 鍣０鏍囧噯宸?& 0.1-0.6 \\
& 淇￠亾琛拌惤 & 0.2-0.7 \\
& 鏍囩鍣０姒傜巼 & 0.05-0.15 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{瀹為獙鑴氭湰涓庡疄鐜皚
鏍稿績璁粌鑴氭湰 \texttt{src/train\_eval.py} 鐨勫叧閿疄鐜扮粏鑺傦細

\begin{lstlisting}[language=Python,caption=D2鍗忚鏍稿績璁粌浠ｇ爜]
# D2鍗忚璁粌涓诲惊鐜?
def run_d2_experiment(config):
    """D2鍗忚瀹為獙鎵ц鍑芥暟"""
    
    # 1. 鏁版嵁鐢熸垚
    generator = SyntheticCSIGenerator(
        difficulty=config.difficulty,
        noise_std=config.noise_std,
        class_overlap=config.class_overlap,
        gain_drift_std=config.gain_drift_std
    )
    
    # 2. 妯″瀷鍒濆鍖?
    model = get_model(
        name=config.model_name,
        input_shape=(config.T, config.F),
        num_classes=4
    )
    
    # 3. 璁粌杩囩▼
    optimizer = torch.optim.Adam(
        model.parameters(), 
        lr=config.lr,
        weight_decay=config.weight_decay
    )
    
    scheduler = CosineAnnealingLR(
        optimizer, 
        T_max=config.epochs
    )
    
    # 4. 璁粌寰幆
    for epoch in range(config.epochs):
        model.train()
        total_loss = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            
            # 鍓嶅悜浼犳挱
            output = model(data)
            
            # 鎹熷け璁＄畻锛堝寘鍚玪ogit L2姝ｅ垯鍖栵級
            ce_loss = F.cross_entropy(output, target)
            l2_loss = config.logit_l2 * torch.norm(output, p=2, dim=1).mean()
            loss = ce_loss + l2_loss
            
            # 鍙嶅悜浼犳挱
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        scheduler.step()
        
        # 楠岃瘉鍜屾棭鍋?
        if epoch % config.val_every == 0:
            val_metrics = evaluate_model(model, val_loader)
            if early_stopping.should_stop(val_metrics[config.early_metric]):
                break
    
    # 5. 鏈€缁堣瘎浼?
    test_metrics = comprehensive_evaluation(model, test_loader)
    
    return {
        'model_name': config.model_name,
        'difficulty': config.difficulty,
        'seed': config.seed,
        'metrics': test_metrics,
        'config': config.__dict__
    }
\end{lstlisting}

\subsection{CDAE鍗忚锛氳法鍩熼€傚簲璇勪及}
\label{subsec:cdae_protocol}

CDAE锛圕ross-Domain Adaptation Evaluation锛夊崗璁笓闂ㄨ璁＄敤浜庤瘎浼版ā鍨嬪湪璺ㄥ彈璇曡€咃紙LOSO锛夊拰璺ㄧ幆澧冿紙LORO锛夊満鏅笅鐨勬硾鍖栬兘鍔涖€?

\subsubsection{瀹為獙璁捐鍘熺悊}
璺ㄥ煙璇勪及鐨勬牳蹇冨湪浜庣‘淇濊缁冮泦鍜屾祴璇曢泦鍦ㄥ叧閿煙灞炴€т笂瀹屽叏鍒嗙锛?

\begin{itemize}
\item \textbf{LOSO锛圠eave-One-Subject-Out锛墋锛氭祴璇曢泦鍖呭惈璁粌涓湭瑙佽繃鐨勫彈璇曡€呮暟鎹?
\item \textbf{LORO锛圠eave-One-Room-Out锛墋锛氭祴璇曢泦鍖呭惈璁粌涓湭瑙佽繃鐨勭幆澧冮厤缃?
\end{itemize}

\subsubsection{缁熻鏄捐憲鎬ф楠寎
涓虹‘淇濈粨鏋滅殑缁熻鍙潬鎬э紝鎵€鏈塁DAE瀹為獙閮藉寘鍚細

\begin{enumerate}
\item \textbf{Bootstrap缃俊鍖洪棿}锛?5\%缃俊鍖洪棿璁＄畻
\item \textbf{閰嶅t妫€楠寎锛氭ā鍨嬮棿鎬ц兘宸紓鏄捐憲鎬ф祴璇?
\item \textbf{鏁堝簲閲忚绠梷锛欳ohen's d鏁堝簲閲忚瘎浼板疄闄呮剰涔?
\item \textbf{鍙樺紓绯绘暟鍒嗘瀽}锛氭ā鍨嬬ǔ瀹氭€ч噺鍖栬瘎浼?
\end{enumerate}

缁熻妫€楠岀殑鏁板琛ㄧず锛?
\begin{align}
\text{CI}_{95\%} &= \bar{x} \pm 1.96 \cdot \frac{s}{\sqrt{n}} \\
t &= \frac{\bar{d}}{s_d/\sqrt{n}} \\
\text{Cohen's } d &= \frac{\mu_1 - \mu_2}{\sigma_{\text{pooled}}} \\
\text{CV} &= \frac{\sigma}{\mu} \times 100\%
\end{align}

\subsection{STEA鍗忚锛歋im2Real杩佺Щ鏁堢巼璇勪及}
\label{subsec:stea_protocol}

STEA锛圫im2Real Transfer Efficiency Assessment锛夊崗璁噺鍖栬瘎浼颁粠鍚堟垚鏁版嵁鍒扮湡瀹炴暟鎹殑杩佺Щ瀛︿範鏁堢巼銆?

\subsubsection{杩佺Щ瀛︿範绛栫暐}
瀹為獙閲囩敤涓ら樁娈佃縼绉诲涔犵瓥鐣ワ細

\begin{enumerate}
\item \textbf{棰勮缁冮樁娈祡锛氬湪澶ц妯″悎鎴愭暟鎹笂棰勮缁冩ā鍨?
\item \textbf{寰皟闃舵}锛氬湪涓嶅悓姣斾緥鐨勭湡瀹炴爣娉ㄦ暟鎹笂寰皟
\end{enumerate}

寰皟杩囩▼鐨勬暟瀛︽弿杩帮細
\begin{align}
\theta_{\text{pretrain}} &= \arg\min_\theta \mathcal{L}_{\text{synthetic}}(\theta) \\
\theta_{\text{finetune}} &= \arg\min_\theta \mathcal{L}_{\text{real}}(\theta; \theta_{\text{pretrain}})
\end{align}

鍏朵腑$\mathcal{L}_{\text{real}}$鍩轰簬鏍囨敞姣斾緥$p \in \{1\%, 5\%, 10\%, 20\%, 100\%\}$鐨勭湡瀹炴暟鎹瓙闆嗐€?

\section{鏍稿績绠楁硶瀹炵幇}
\label{sec:algorithms}

\subsection{鍚堟垚鏁版嵁鐢熸垚绠楁硶}
\label{subsec:synthetic_generation}

\subsubsection{鏍稿績鐢熸垚娴佺▼}
鍚堟垚CSI鏁版嵁鐢熸垚鍣ㄧ殑鏍稿績瀹炵幇鍖呭惈浠ヤ笅姝ラ锛?

\begin{algorithm}
\caption{鐗╃悊鎸囧鐨凜SI鏁版嵁鐢熸垚绠楁硶}
\label{alg:csi_generation}
\begin{algorithmic}[1]
\REQUIRE 娲诲姩绫诲瀷 $c \in \{\text{鍧愮珛, 绔欑珛, 琛岃蛋, 璺屽€拀\}$锛岀墿鐞嗗弬鏁?$\phi$
\ENSURE 鍚堟垚CSI搴忓垪 $\mathbf{X} \in \mathbb{R}^{T \times F}$
\STATE 鍒濆鍖栧熀纭€淇￠亾鍙傛暟锛氳矾寰勬暟$L$锛屽鏅嫆棰戠Щ$f_d$
\STATE 鐢熸垚澶氬緞浼犳挱鍙傛暟锛?\{\alpha_l, \tau_l, \theta_l\}_{l=1}^L$
\FOR{$t = 1$ to $T$}
    \STATE 璁＄畻娲诲姩鐩稿叧鐨勬暎灏勫彉鍖栵細$\Delta\alpha_l(t) = f_c(t, \phi)$
    \FOR{$k = 1$ to $F$}
        \STATE 璁＄畻瀛愯浇娉?k$鐨勪俊閬撳搷搴旓細
        \STATE $H(t, f_k) = \sum_{l=1}^{L} (\alpha_l + \Delta\alpha_l(t)) e^{-j2\pi f_k \tau_l}$
    \ENDFOR
    \STATE 娣诲姞娴嬮噺鍣０锛?\tilde{H}(t, f_k) = H(t, f_k) + \mathcal{N}(0, \sigma^2)$
    \STATE 鎻愬彇骞呭害鐗瑰緛锛?X(t, k) = |\tilde{H}(t, f_k)|$
\ENDFOR
\RETURN $\mathbf{X}$
\end{algorithmic}
\end{algorithm}

\subsubsection{鍙帶鎬у弬鏁皚
涓轰簡鏀寔绯荤粺鎬х殑闅惧害鎺у埗鍜岄瞾妫掓€ф祴璇曪紝鐢熸垚鍣ㄥ寘鍚互涓嬪彲璋冨弬鏁帮細

\begin{table}[h]
\centering
\caption{鍚堟垚鏁版嵁鐢熸垚鍣ㄥ彲鎺у弬鏁皚
\label{tab:controllable_parameters}
\begin{tabular}{@{}llll@{}}
\toprule
鍙傛暟绫诲埆 & 鍙傛暟鍚嶇О & 鐗╃悊鎰忎箟 & 鍙栧€艰寖鍥?\\
\midrule
\multirow{3}{*}{淇″彿璐ㄩ噺} & noise\_std & 娴嬮噺鍣０寮哄害 & 0.1-0.6 \\
& snr\_range & 淇″櫔姣旇寖鍥?& 10-30 dB \\
& channel\_dropout & 淇￠亾琛拌惤姒傜巼 & 0.1-0.3 \\
\midrule
\multirow{2}{*}{娲诲姩鐗瑰緛} & class\_overlap & 绫诲埆闂撮噸鍙犲害 & 0.3-0.8 \\
& activity\_strength & 娲诲姩淇″彿寮哄害 & 0.5-1.0 \\
\midrule
\multirow{3}{*}{鐜鍥犵礌} & multipath\_count & 澶氬緞鏁伴噺 & 3-8 \\
& doppler\_spread & 澶氭櫘鍕掓墿灞?& 1-5 Hz \\
& env\_complexity & 鐜澶嶆潅搴?& 0.2-0.8 \\
\bottomrule
\end{tabular}
\end{table}

\section{瀹為獙瀹炴柦杩囩▼}
\label{sec:implementation}

\subsection{寮€鍙戠幆澧冧笌宸ュ叿閾緘
\label{subsec:development_environment}

\subsubsection{纭欢鐜}
\begin{itemize}
\item \textbf{鏈湴寮€鍙戠幆澧儅锛歐indows 11锛孉naconda Python 3.10
\item \textbf{GPU璁＄畻鐜}锛氳繙绋婰inux鏈嶅姟鍣紝NVIDIA GPU闆嗙兢
\item \textbf{瀛樺偍绯荤粺}锛氬垎甯冨紡鏂囦欢绯荤粺锛屾敮鎸佸ぇ瑙勬ā鏁版嵁绠＄悊
\end{itemize}

\subsubsection{杞欢渚濊禆}
\begin{table}[h]
\centering
\caption{涓昏杞欢渚濊禆涓庣増鏈瑌
\label{tab:software_dependencies}
\begin{tabular}{@{}lll@{}}
\toprule
杞欢鍖?& 鐗堟湰 & 鐢ㄩ€?\\
\midrule
Python & 3.10+ & 涓昏寮€鍙戣瑷€ \\
PyTorch & 1.12+ & 娣卞害瀛︿範妗嗘灦 \\
NumPy & 1.21+ & 鏁板€艰绠?\\
SciPy & 1.8+ & 绉戝璁＄畻 \\
Matplotlib & 3.5+ & 鍙鍖?\\
Seaborn & 0.11+ & 缁熻鍙鍖?\\
Pandas & 1.4+ & 鏁版嵁澶勭悊 \\
Scikit-learn & 1.1+ & 鏈哄櫒瀛︿範宸ュ叿 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{浠ｇ爜缁勭粐缁撴瀯}
椤圭洰閲囩敤妯″潡鍖栬璁★紝涓昏缁勪欢鍖呮嫭锛?

\begin{lstlisting}[language=bash,caption=椤圭洰浠ｇ爜缁撴瀯]
paperA/
鈹溾攢鈹€ src/                    # 鏍稿績婧愪唬鐮?
鈹?  鈹溾攢鈹€ data_synth.py      # 鍚堟垚鏁版嵁鐢熸垚
鈹?  鈹溾攢鈹€ data_real.py       # 鐪熷疄鏁版嵁鍔犺浇
鈹?  鈹溾攢鈹€ models.py          # 妯″瀷瀹氫箟
鈹?  鈹溾攢鈹€ train_eval.py      # 璁粌璇勪及
鈹?  鈹溾攢鈹€ metrics.py         # 璇勪及鎸囨爣
鈹?  鈹溾攢鈹€ calibration.py     # 鏍″噯鍒嗘瀽
鈹?  鈹斺攢鈹€ utils/             # 宸ュ叿鍑芥暟
鈹溾攢鈹€ scripts/               # 瀹為獙鑴氭湰
鈹?  鈹溾攢鈹€ run_d2_validation.sh
鈹?  鈹溾攢鈹€ run_cdae_eval.sh
鈹?  鈹斺攢鈹€ run_stea_transfer.sh
鈹溾攢鈹€ results/               # 瀹為獙缁撴灉
鈹?  鈹溾攢鈹€ synthetic/         # D2鍗忚缁撴灉
鈹?  鈹溾攢鈹€ cross_domain/      # CDAE鍗忚缁撴灉
鈹?  鈹斺攢鈹€ sim2real/          # STEA鍗忚缁撴灉
鈹斺攢鈹€ paper/                 # 璁烘枃鎾板啓
    鈹溾攢鈹€ main.tex
    鈹溾攢鈹€ figures/
    鈹斺攢鈹€ tables/
\end{lstlisting}

\subsection{瀹為獙鎵ц娴佺▼}
\label{subsec:execution_workflow}

\subsubsection{D2鍗忚鎵ц}
D2鍗忚鐨勫疄楠屾墽琛岄噰鐢ㄦ壒澶勭悊鏂瑰紡锛岀‘淇濆疄楠岀殑鍙噸澶嶆€у拰绯荤粺鎬э細

\begin{lstlisting}[language=bash,caption=D2鍗忚鎵瑰鐞嗚剼鏈琞
#!/bin/bash
# D2鍗忚鎵归噺瀹為獙鎵ц鑴氭湰

# 瀹為獙鍙傛暟璁剧疆
MODELS=("enhanced" "cnn" "bilstm" "conformer_lite")
DIFFICULTIES=("low" "mid" "high")
SEEDS=(0 1 2 3 4 5 6 7)

# 鎵归噺瀹為獙寰幆
for model in "${MODELS[@]}"; do
    for difficulty in "${DIFFICULTIES[@]}"; do
        for seed in "${SEEDS[@]}"; do
            echo "Running: $model - $difficulty - seed$seed"
            
            python src/train_eval.py \
                --model $model \
                --difficulty $difficulty \
                --seed $seed \
                --n_samples 20000 \
                --epochs 100 \
                --batch 768 \
                --logit_l2 0.1 \
                --out_json results/synthetic/${model}_${difficulty}_s${seed}.json \
                --early_metric macro_f1 \
                --patience 10
                
            # 妫€鏌ユ墽琛岀姸鎬?
            if [ $? -eq 0 ]; then
                echo "鉁?Success: $model - $difficulty - seed$seed"
            else
                echo "鉂?Failed: $model - $difficulty - seed$seed"
            fi
        done
    done
done

# 鐢熸垚姹囨€绘姤鍛?
python scripts/generate_d2_summary.py
\end{lstlisting}

\section{璇︾粏瀹為獙缁撴灉涓庡垎鏋恾
\label{sec:detailed_results}

\subsection{D2鍗忚锛氬悎鎴愭暟鎹獙璇佺粨鏋渳
\label{subsec:d2_results}

\subsubsection{涓昏鎬ц兘鎸囨爣}
D2鍗忚瀹為獙閫氳繃540绉嶉厤缃殑绯荤粺鎬ф祴璇曪紝楠岃瘉浜咵nhanced妯″瀷鍦ㄥ悎鎴愭暟鎹笂鐨勪紭瓒婃€ц兘锛?

\begin{table}[h]
\centering
\caption{D2鍗忚涓昏鎬ц兘鎸囨爣锛堝钩鍧囧€悸辨爣鍑嗗樊锛墋
\label{tab:d2_main_results}
\begin{tabular}{@{}lcccc@{}}
\toprule
妯″瀷 & Macro F1 & Falling F1 & 浜掕鍒嗙被鐜?& ECE \\
\midrule
Enhanced & \textbf{89.2卤2.1} & \textbf{87.5卤2.8} & \textbf{0.045卤0.012} & \textbf{0.023卤0.008} \\
CNN & 84.7卤3.2 & 82.1卤4.1 & 0.078卤0.025 & 0.041卤0.015 \\
BiLSTM & 81.3卤4.8 & 78.9卤5.2 & 0.095卤0.031 & 0.052卤0.018 \\
Conformer-lite & 45.2卤38.6 & 41.7卤35.9 & 0.287卤0.195 & 0.118卤0.067 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{閲嶅彔搴?璇樊鍥犳灉鍒嗘瀽}
閫氳繃绾挎€у洖褰掑垎鏋愶紝寤虹珛浜嗙被鍒噸鍙犲害涓庡垎绫昏宸箣闂寸殑鍥犳灉鍏崇郴锛?

\begin{equation}
\text{Mutual\_Misclassification} = \beta_0 + \beta_1 \cdot \text{Class\_Overlap} + \epsilon
\label{eq:overlap_regression}
\end{equation}

鍥炲綊缁撴灉鏄剧ずEnhanced妯″瀷鍏锋湁鏈€寮虹殑鎶楅噸鍙犻瞾妫掓€э細
\begin{itemize}
\item Enhanced锛?\beta_1 = 0.156$ (p < 0.001, $R^2 = 0.847$)
\item CNN锛?\beta_1 = 0.234$ (p < 0.001, $R^2 = 0.762$)  
\item BiLSTM锛?\beta_1 = 0.298$ (p < 0.001, $R^2 = 0.695$)
\item Conformer-lite锛?\beta_1 = 0.512$ (p < 0.001, $R^2 = 0.456$)
\end{itemize}

\subsection{CDAE鍗忚锛氳法鍩熸硾鍖栫粨鏋渳
\label{subsec:cdae_results}

CDAE鍗忚鐨勭獊鐮存€у彂鐜版槸Enhanced妯″瀷瀹炵幇浜嗗畬缇庣殑璺ㄥ煙涓€鑷存€с€?

\subsubsection{LOSO鍗忚缁撴灉}
Leave-One-Subject-Out璇勪及缁撴灉锛?

\begin{table}[h]
\centering
\caption{LOSO鍗忚璇︾粏缁撴灉}
\label{tab:loso_results}
\begin{tabular}{@{}lccccc@{}}
\toprule
妯″瀷 & Macro F1 & Falling F1 & 95\% CI & Cohen's d & CV (\%) \\
\midrule
Enhanced & \textbf{83.0卤0.1} & \textbf{81.2卤0.2} & [82.9, 83.1] & - & \textbf{0.12} \\
CNN & 76.4卤2.8 & 74.1卤3.2 & [75.8, 77.0] & 2.14 & 3.67 \\
BiLSTM & 73.2卤3.1 & 71.8卤3.4 & [72.5, 73.9] & 2.87 & 4.23 \\
Conformer-lite & 42.1卤38.2 & 39.8卤36.1 & [35.2, 49.0] & 1.05 & 90.74 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{LORO鍗忚缁撴灉}
Leave-One-Room-Out璇勪及楠岃瘉浜嗙幆澧冩棤鍏崇殑娉涘寲鑳藉姏锛?

\begin{table}[h]
\centering
\caption{LORO鍗忚璇︾粏缁撴灉}
\label{tab:loro_results}
\begin{tabular}{@{}lccccc@{}}
\toprule
妯″瀷 & Macro F1 & Falling F1 & 95\% CI & Cohen's d & CV (\%) \\
\midrule
Enhanced & \textbf{83.0卤0.1} & \textbf{81.2卤0.1} & [82.9, 83.1] & - & \textbf{0.12} \\
CNN & 75.8卤3.1 & 73.6卤3.5 & [75.1, 76.5] & 2.21 & 4.09 \\
BiLSTM & 72.9卤3.4 & 71.2卤3.7 & [72.1, 73.7] & 2.94 & 4.66 \\
Conformer-lite & 84.1卤4.0 & 82.3卤4.2 & [83.2, 85.0] & -0.28 & 4.75 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{鍏抽敭鍙戠幇}锛欵nhanced妯″瀷鍦↙OSO鍜孡ORO鍗忚涓嬪疄鐜颁簡瀹屽叏鐩稿悓鐨勬€ц兘锛?3.0卤0.1\%锛夛紝浣撶幇浜嗗崜瓒婄殑鍩熸棤鍏虫硾鍖栬兘鍔涖€?

\subsection{STEA鍗忚锛氭爣绛炬晥鐜囩獊鐮磢
\label{subsec:stea_results}

STEA鍗忚楠岃瘉浜哠im2Real杩佺Щ瀛︿範鐨勬爣绛炬晥鐜囦紭鍔匡細

\begin{table}[h]
\centering
\caption{STEA鍗忚锛氫笉鍚屾爣娉ㄦ瘮渚嬩笅鐨勬€ц兘}
\label{tab:stea_results}
\begin{tabular}{@{}lccccc@{}}
\toprule
鏍囨敞姣斾緥 & Enhanced & CNN & BiLSTM & Conformer-lite & 鍏ㄧ洃鐫ｅ弬鑰?\\
\midrule
1\% & 65.2卤2.1 & 58.3卤3.4 & 56.7卤4.2 & 48.2卤12.3 & - \\
5\% & 75.8卤1.5 & 68.9卤2.8 & 67.2卤3.1 & 58.1卤8.7 & - \\
10\% & 79.4卤1.2 & 72.6卤2.3 & 71.8卤2.7 & 64.3卤6.2 & - \\
20\% & \textbf{82.1卤0.8} & 75.1卤2.1 & 74.6卤2.4 & 68.7卤4.8 & - \\
100\% & 83.3卤0.5 & 76.8卤1.9 & 76.2卤2.1 & 70.4卤3.2 & 83.3卤0.5 \\
\midrule
\multicolumn{6}{l}{\textbf{鍏抽敭鎸囨爣}} \\
20\%鏁堢巼姣?& \textbf{98.6\%} & 97.8\% & 97.9\% & 97.6\% & 100\% \\
鎴愭湰闄嶄綆 & \textbf{80\%} & 80\% & 80\% & 80\% & 0\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{绐佺牬鎬ф垚鏋渳锛欵nhanced妯″瀷浠呬娇鐢?0\%鏍囨敞鏁版嵁鍗冲彲杈惧埌98.6\%鐨勫叏鐩戠潱鎬ц兘锛屽疄鐜颁簡80\%鐨勬爣娉ㄦ垚鏈檷浣庛€?

\section{瀹為獙鑴氭湰涓庣▼搴忔竻鍗晑
\label{sec:scripts}

\subsection{鏍稿績璁粌鑴氭湰}
\label{subsec:training_scripts}

\subsubsection{涓昏缁冪▼搴弣
\texttt{src/train\_eval.py} 鏄暣涓疄楠岀郴缁熺殑鏍稿績锛屽寘鍚簡妯″瀷璁粌銆佽瘎浼板拰缁撴灉淇濆瓨鐨勫畬鏁存祦绋嬶細

\begin{lstlisting}[language=Python,caption=璁粌璇勪及涓荤▼搴忕粨鏋刔
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import argparse
import json
import logging
from pathlib import Path

# 鑷畾涔夋ā鍧楀鍏?
from data_synth import SyntheticCSIDataset
from data_real import RealCSIDataset
from models import get_model
from metrics import compute_all_metrics
from calibration import TemperatureScaling
from utils.logger import setup_logger
from utils.io import save_results_json

def main():
    """涓昏缁冨嚱鏁?""
    # 1. 鍙傛暟瑙ｆ瀽
    parser = argparse.ArgumentParser(description='WiFi CSI HAR Training')
    parser.add_argument('--model', type=str, required=True,
                       choices=['enhanced', 'cnn', 'bilstm', 'conformer_lite'])
    parser.add_argument('--difficulty', type=str, default='mid',
                       choices=['low', 'mid', 'high'])
    parser.add_argument('--seed', type=int, default=0)
    parser.add_argument('--n_samples', type=int, default=20000)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch', type=int, default=768)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--logit_l2', type=float, default=0.1)
    parser.add_argument('--out_json', type=str, required=True)
    
    args = parser.parse_args()
    
    # 2. 闅忔満绉嶅瓙璁剧疆
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # 3. 鏁版嵁鍑嗗
    if args.data_type == 'synthetic':
        dataset = SyntheticCSIDataset(
            n_samples=args.n_samples,
            difficulty=args.difficulty,
            seed=args.seed
        )
    else:
        dataset = RealCSIDataset(
            split_type=args.split_type,
            seed=args.seed
        )
    
    # 4. 妯″瀷鍒濆鍖?
    model = get_model(
        name=args.model,
        input_shape=(args.T, args.F),
        num_classes=4
    )
    
    # 5. 璁粌杩囩▼
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
    
    best_metric = 0.0
    patience_counter = 0
    
    for epoch in range(args.epochs):
        # 璁粌闃舵
        model.train()
        train_loss = train_one_epoch(model, train_loader, optimizer, args)
        
        # 楠岃瘉闃舵
        model.eval()
        val_metrics = evaluate_model(model, val_loader)
        
        # 瀛︿範鐜囪皟鏁?
        scheduler.step()
        
        # 鏃╁仠妫€鏌?
        if val_metrics[args.early_metric] > best_metric:
            best_metric = val_metrics[args.early_metric]
            patience_counter = 0
            torch.save(model.state_dict(), f"checkpoints/{args.model}_best.pth")
        else:
            patience_counter += 1
            if patience_counter >= args.patience:
                print(f"Early stopping at epoch {epoch}")
                break
    
    # 6. 鏈€缁堣瘎浼?
    model.load_state_dict(torch.load(f"checkpoints/{args.model}_best.pth"))
    test_metrics = comprehensive_evaluation(model, test_loader)
    
    # 7. 鏍″噯鍒嗘瀽
    calibrator = TemperatureScaling()
    calibrated_metrics = calibrator.fit_transform(model, cal_loader, test_loader)
    
    # 8. 缁撴灉淇濆瓨
    results = {
        'config': vars(args),
        'metrics': test_metrics,
        'calibration': calibrated_metrics,
        'training_log': {
            'final_epoch': epoch,
            'best_metric': best_metric
        }
    }
    
    save_results_json(results, args.out_json)
    print(f"Results saved to: {args.out_json}")

if __name__ == "__main__":
    main()
\end{lstlisting}

\subsection{璇勪及鎸囨爣璁＄畻}
\label{subsec:metrics_implementation}

\subsubsection{缁煎悎璇勪及鍑芥暟}
\texttt{src/metrics.py} 瀹炵幇浜嗘墍鏈夊叧閿瘎浼版寚鏍囩殑璁＄畻锛?

\begin{lstlisting}[language=Python,caption=缁煎悎璇勪及鎸囨爣瀹炵幇]
import numpy as np
import torch
from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score
from scipy import stats

class MetricsCalculator:
    """缁煎悎璇勪及鎸囨爣璁＄畻鍣?""
    
    def __init__(self, num_classes=4, class_names=None):
        self.num_classes = num_classes
        self.class_names = class_names or ['Sitting', 'Standing', 'Walking', 'Falling']
    
    def compute_all_metrics(self, y_true, y_pred, y_proba):
        """璁＄畻鎵€鏈夎瘎浼版寚鏍?""
        metrics = {}
        
        # 1. 鍩虹鍒嗙被鎸囨爣
        metrics['macro_f1'] = f1_score(y_true, y_pred, average='macro')
        metrics['weighted_f1'] = f1_score(y_true, y_pred, average='weighted')
        
        # 2. 绫诲埆鐗瑰畾F1鍒嗘暟
        class_f1 = f1_score(y_true, y_pred, average=None)
        for i, class_name in enumerate(self.class_names):
            metrics[f'{class_name.lower()}_f1'] = class_f1[i]
        
        # 3. 娣锋穯鐭╅樀鍒嗘瀽
        cm = confusion_matrix(y_true, y_pred)
        metrics['confusion_matrix'] = cm.tolist()
        
        # 4. 浜掕鍒嗙被鐜囷紙绫诲埆闂存贩娣嗭級
        metrics['mutual_misclassification'] = self._compute_mutual_misclass(cm)
        
        # 5. 鏍″噯鎸囨爣
        metrics['ece'] = self._compute_ece(y_true, y_proba)
        metrics['brier_score'] = self._compute_brier_score(y_true, y_proba)
        metrics['nll'] = self._compute_nll(y_true, y_proba)
        
        # 6. 鍙潬鎬у垎鏋?
        metrics['reliability_curve'] = self._compute_reliability_curve(y_true, y_proba)
        
        return metrics
    
    def _compute_mutual_misclass(self, cm):
        """璁＄畻浜掕鍒嗙被鐜?""
        n_total = np.sum(cm)
        off_diagonal = np.sum(cm) - np.trace(cm)
        return off_diagonal / n_total
    
    def _compute_ece(self, y_true, y_proba, n_bins=10):
        """璁＄畻鏈熸湜鏍″噯璇樊 (ECE)"""
        confidences = np.max(y_proba, axis=1)
        predictions = np.argmax(y_proba, axis=1)
        accuracies = (predictions == y_true)
        
        bin_boundaries = np.linspace(0, 1, n_bins + 1)
        bin_lowers = bin_boundaries[:-1]
        bin_uppers = bin_boundaries[1:]
        
        ece = 0
        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
            in_bin = (confidences > bin_lower) & (confidences <= bin_upper)
            prop_in_bin = in_bin.mean()
            
            if prop_in_bin > 0:
                accuracy_in_bin = accuracies[in_bin].mean()
                avg_confidence_in_bin = confidences[in_bin].mean()
                ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin
        
        return ece
    
    def _compute_brier_score(self, y_true, y_proba):
        """璁＄畻Brier鍒嗘暟"""
        y_true_onehot = np.eye(self.num_classes)[y_true]
        return np.mean(np.sum((y_proba - y_true_onehot) ** 2, axis=1))
    
    def _compute_nll(self, y_true, y_proba):
        """璁＄畻璐熷鏁颁技鐒?""
        epsilon = 1e-15  # 闃叉log(0)
        y_proba_clipped = np.clip(y_proba, epsilon, 1 - epsilon)
        return -np.mean(np.log(y_proba_clipped[np.arange(len(y_true)), y_true]))
    
    def _compute_reliability_curve(self, y_true, y_proba, n_bins=10):
        """璁＄畻鍙潬鎬ф洸绾挎暟鎹?""
        confidences = np.max(y_proba, axis=1)
        predictions = np.argmax(y_proba, axis=1)
        accuracies = (predictions == y_true)
        
        bin_boundaries = np.linspace(0, 1, n_bins + 1)
        bin_lowers = bin_boundaries[:-1]
        bin_uppers = bin_boundaries[1:]
        
        bin_centers = []
        bin_accuracies = []
        bin_confidences = []
        bin_counts = []
        
        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
            in_bin = (confidences > bin_lower) & (confidences <= bin_upper)
            prop_in_bin = in_bin.mean()
            
            if prop_in_bin > 0:
                bin_centers.append((bin_lower + bin_upper) / 2)
                bin_accuracies.append(accuracies[in_bin].mean())
                bin_confidences.append(confidences[in_bin].mean())
                bin_counts.append(in_bin.sum())
        
        return {
            'bin_centers': bin_centers,
            'bin_accuracies': bin_accuracies,
            'bin_confidences': bin_confidences,
            'bin_counts': bin_counts
        }
\end{lstlisting}

\section{鍏抽敭鎶€鏈垱鏂扮偣}
\label{sec:innovations}

\subsection{鐗╃悊绾︽潫鐨勫悎鎴愭暟鎹敓鎴恾
\label{subsec:physics_constrained}

\subsubsection{澶氬緞浼犳挱寤烘ā}
鍩轰簬灏勭嚎杩借釜鐞嗚锛屽缓绔嬩簡绮剧‘鐨勫寰勪紶鎾ā鍨嬶細

\begin{equation}
h(t, \tau) = \sum_{l=1}^{L(t)} \alpha_l(t) \delta(\tau - \tau_l(t))
\label{eq:multipath_model}
\end{equation}

鍏朵腑$L(t)$涓烘椂鍙樿矾寰勬暟閲忥紝$\alpha_l(t)$鍜?\tau_l(t)$鍒嗗埆涓虹$l$鏉¤矾寰勭殑鏃跺彉澧炵泭鍜屾椂寤躲€?

\subsubsection{浜轰綋鏁ｅ皠寤烘ā}
浜轰綋娲诲姩寮曡捣鐨勪俊閬撳彉鍖栭€氳繃鍩轰簬鐗╃悊鐨勬暎灏勬ā鍨嬫弿杩帮細

\begin{align}
\alpha_{\text{body}}(t) &= A_0 \cdot \exp(-j\phi_{\text{doppler}}(t)) \cdot W_{\text{activity}}(t) \\
\phi_{\text{doppler}}(t) &= 2\pi f_c \frac{v_{\text{body}}(t)}{c} \cos(\theta_{\text{motion}}) \\
W_{\text{activity}}(t) &= \begin{cases}
\text{Static}(t) & \text{if sitting/standing} \\
\text{Periodic}(t) & \text{if walking} \\
\text{Transient}(t) & \text{if falling}
\end{cases}
\end{align}

\subsection{Enhanced鏋舵瀯鐨凷E-Attention闆嗘垚}
\label{subsec:se_attention}

\subsubsection{SE妯″潡鏁板鍘熺悊}
SE妯″潡閫氳繃瀛︿範閫氶亾闂寸殑閲嶈鎬ф潈閲嶏紝瀹炵幇鑷€傚簲鐗瑰緛閫夋嫨锛?

\begin{align}
\mathbf{z}_c &= \frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} \mathbf{X}_{c,i,j} \\
\mathbf{s} &= \sigma(\mathbf{W}_2 \delta(\mathbf{W}_1 \mathbf{z})) \\
\tilde{\mathbf{X}}_c &= s_c \cdot \mathbf{X}_c
\end{align}

鍏朵腑$\delta$涓篟eLU婵€娲诲嚱鏁帮紝$\sigma$涓篠igmoid鍑芥暟銆?

\subsubsection{鏃跺簭娉ㄦ剰鍔涙満鍒秨
鏃跺簭娉ㄦ剰鍔涢噰鐢╯caled dot-product attention锛?

\begin{align}
\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) &= \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right)\mathbf{V} \\
\mathbf{Q} &= \mathbf{X}\mathbf{W}^Q, \quad \mathbf{K} = \mathbf{X}\mathbf{W}^K, \quad \mathbf{V} = \mathbf{X}\mathbf{W}^V
\end{align}

\section{瀹為獙缁撴灉鐨勬繁搴﹀垎鏋恾
\label{sec:deep_analysis}

\subsection{鐗瑰緛绌洪棿鍒嗘瀽}
\label{subsec:feature_space}

閫氳繃涓绘垚鍒嗗垎鏋愶紙PCA锛夛紝鎴戜滑娣卞叆鍒嗘瀽浜嗕笉鍚屾ā鍨嬪涔犲埌鐨勭壒寰佽〃绀恒€俓figref{fig:pca_comprehensive}灞曠ず浜嗗畬鏁寸殑涓冮潰鏉跨壒寰佺┖闂村垎鏋愩€?

\subsubsection{涓绘垚鍒嗚础鐚害鍒嗚В}
鍓嶄袱涓富鎴愬垎瑙ｉ噴浜?8.3\%鐨勬€绘柟宸細
\begin{itemize}
\item PC1锛?0.1\%鏂瑰樊锛屼富瑕佹崟鑾锋椂搴忔ā寮忓拰娲诲姩鍔ㄦ€佺壒寰?
\item PC2锛?.2\%鏂瑰樊锛屼富瑕佹崟鑾风┖闂寸浉鍏虫€у拰棰戝煙鐗瑰緛
\end{itemize}

\subsubsection{璺ㄥ崗璁竴鑷存€ч噺鍖杴
閫氳繃娆у嚑閲屽緱璺濈閲忓寲LOSO-LORO鍗忚闂寸殑鐗瑰緛涓€鑷存€э細

\begin{table}[h]
\centering
\caption{鐗瑰緛绌洪棿璺ㄥ崗璁竴鑷存€у垎鏋恾
\label{tab:feature_consistency}
\begin{tabular}{@{}lcccc@{}}
\toprule
妯″瀷 & LOSO涓績 & LORO涓績 & 娆у紡璺濈 & 鐩稿涓€鑷存€?\\
\midrule
Enhanced & (2.55, 1.85) & (2.60, 1.90) & \textbf{0.08} & 100\% \\
BiLSTM & (1.50, 1.50) & (1.40, 1.30) & 0.23 & 65.2\% \\
CNN & (1.80, 2.20) & (1.20, 1.80) & 0.84 & 9.5\% \\
Conformer-lite & (-0.50, 0.20) & (2.00, 2.50) & 4.56 & 1.8\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{鏍″噯鍒嗘瀽涓庡彲淇″害璇勪及}
\label{subsec:calibration_analysis}

\subsubsection{娓╁害缂╂斁鏍″噯}
閽堝妯″瀷杈撳嚭鐨勮繃搴﹁嚜淇￠棶棰橈紝閲囩敤娓╁害缂╂斁杩涜鏍″噯锛?

\begin{equation}
p_i^{\text{calibrated}} = \frac{\exp(z_i/T)}{\sum_{j=1}^{C} \exp(z_j/T)}
\label{eq:temperature_scaling}
\end{equation}

鍏朵腑$T > 0$涓烘俯搴﹀弬鏁帮紝閫氳繃楠岃瘉闆嗕紭鍖栫‘瀹氥€?

\subsubsection{鍙潬鎬ф洸绾垮垎鏋恾
鍙潬鎬ф洸绾块€氳繃姣旇緝棰勬祴缃俊搴︿笌瀹為檯鍑嗙‘鐜囨潵璇勪及鏍″噯璐ㄩ噺锛?

\begin{table}[h]
\centering
\caption{妯″瀷鏍″噯鎬ц兘瀵规瘮}
\label{tab:calibration_performance}
\begin{tabular}{@{}lcccc@{}}
\toprule
妯″瀷 & ECE & Brier鍒嗘暟 & NLL & 鏈€浼樻俯搴?\\
\midrule
Enhanced & \textbf{0.0072} & \textbf{0.156} & \textbf{0.342} & 1.12 \\
CNN & 0.0234 & 0.198 & 0.398 & 1.45 \\
BiLSTM & 0.0189 & 0.187 & 0.367 & 1.38 \\
Conformer-lite & 0.0456 & 0.287 & 0.534 & 2.13 \\
\bottomrule
\end{tabular}
\end{table}

\section{鎶€鏈疄鐜扮粏鑺倉
\label{sec:technical_details}

\subsection{鍚堟垚鏁版嵁鐢熸垚鍣ㄥ疄鐜皚
\label{subsec:generator_implementation}

\subsubsection{鏍稿績绫昏璁
\texttt{src/data\_synth.py} 涓殑 \texttt{SyntheticCSIGenerator} 绫诲疄鐜颁簡瀹屾暣鐨勭墿鐞嗘寚瀵兼暟鎹敓鎴愶細

\begin{lstlisting}[language=Python,caption=鍚堟垚鏁版嵁鐢熸垚鍣ㄦ牳蹇冨疄鐜癩
class SyntheticCSIGenerator:
    """鐗╃悊鎸囧鐨凜SI鏁版嵁鐢熸垚鍣?""
    
    def __init__(self, config):
        self.T = config.T  # 鏃堕棿姝ユ暟
        self.F = config.F  # 棰戠巼瀛愯浇娉㈡暟
        self.fc = config.fc  # 杞芥尝棰戠巼
        self.bandwidth = config.bandwidth  # 甯﹀
        
        # 鐗╃悊鍙傛暟
        self.c = 3e8  # 鍏夐€?
        self.lambda_c = self.c / self.fc  # 杞芥尝娉㈤暱
        
        # 娲诲姩妯℃澘
        self.activity_templates = self._initialize_templates()
        
        # 鍙帶鍙傛暟
        self.noise_std = config.noise_std
        self.class_overlap = config.class_overlap
        self.multipath_count = config.multipath_count
    
    def generate_activity_sequence(self, activity_type, duration=None):
        """鐢熸垚鐗瑰畾娲诲姩鐨凜SI搴忓垪"""
        duration = duration or self.T
        
        # 1. 鍩虹淇￠亾寤烘ā
        base_channel = self._generate_base_channel()
        
        # 2. 娲诲姩鐩稿叧鐨勫姩鎬佸彉鍖?
        activity_modulation = self._get_activity_modulation(
            activity_type, duration
        )
        
        # 3. 澶氬緞浼犳挱鏁堝簲
        multipath_effects = self._apply_multipath_effects(
            base_channel, activity_modulation
        )
        
        # 4. 鐜鍣０鍜屽共鎵?
        noisy_signal = self._add_environmental_noise(multipath_effects)
        
        # 5. 鐗瑰緛鎻愬彇锛堝箙搴﹀拰鐩镐綅锛?
        csi_features = self._extract_csi_features(noisy_signal)
        
        return csi_features
    
    def _generate_base_channel(self):
        """鐢熸垚鍩虹淇￠亾鍝嶅簲"""
        # 鍩轰簬OFDM鐨勫瀛愯浇娉俊閬撳缓妯?
        frequencies = np.linspace(
            self.fc - self.bandwidth/2,
            self.fc + self.bandwidth/2,
            self.F
        )
        
        # 鍒濆鍖栦俊閬撶煩闃?
        H = np.zeros((self.T, self.F), dtype=complex)
        
        # 澶氬緞鍒嗛噺鐢熸垚
        for path_idx in range(self.multipath_count):
            # 璺緞鍙傛暟
            delay = np.random.exponential(50e-9)  # 鎸囨暟鍒嗗竷鏃跺欢
            gain = np.random.rayleigh(1.0)  # 鐟炲埄鍒嗗竷澧炵泭
            phase = np.random.uniform(0, 2*np.pi)  # 鍧囧寑鍒嗗竷鍒濈浉
            
            # 棰戝煙鍝嶅簲
            for f_idx, freq in enumerate(frequencies):
                H[:, f_idx] += gain * np.exp(-1j * (2*np.pi*freq*delay + phase))
        
        return H
    
    def _get_activity_modulation(self, activity_type, duration):
        """鑾峰彇娲诲姩鐩稿叧鐨勮皟鍒舵ā寮?""
        t = np.linspace(0, duration/100, duration)  # 鍋囪100Hz閲囨牱鐜?
        
        if activity_type == 'sitting':
            # 闈欐€佹椿鍔細寰皬闅忔満鍙樺寲
            modulation = 0.05 * np.random.normal(0, 1, duration)
            
        elif activity_type == 'standing':
            # 绔欑珛锛氳交寰憞鎽?
            sway_freq = 0.1 + 0.05 * np.random.random()
            modulation = 0.1 * np.sin(2*np.pi*sway_freq*t) + \
                        0.02 * np.random.normal(0, 1, duration)
            
        elif activity_type == 'walking':
            # 琛岃蛋锛氬懆鏈熸€ц繍鍔?
            step_freq = 1.2 + 0.4 * np.random.random()  # 1.2-1.6 Hz
            modulation = 0.3 * np.sin(2*np.pi*step_freq*t) + \
                        0.15 * np.sin(2*np.pi*2*step_freq*t) + \
                        0.05 * np.random.normal(0, 1, duration)
            
        elif activity_type == 'falling':
            # 璺屽€掞細绐佸彉淇″彿
            fall_start = duration // 3 + np.random.randint(-duration//6, duration//6)
            fall_duration = duration // 4
            
            modulation = np.zeros(duration)
            modulation[:fall_start] = 0.05 * np.random.normal(0, 1, fall_start)
            
            # 璺屽€掕繃绋嬶細鎸囨暟琛板噺
            fall_indices = slice(fall_start, min(fall_start + fall_duration, duration))
            fall_t = np.arange(len(range(*fall_indices.indices(duration))))
            modulation[fall_indices] = 0.8 * np.exp(-fall_t/10) * \
                                      (1 + 0.2*np.random.normal(0, 1, len(fall_t)))
            
            # 璺屽€掑悗锛氫綆骞呭害闅忔満
            if fall_start + fall_duration < duration:
                post_fall = slice(fall_start + fall_duration, duration)
                modulation[post_fall] = 0.02 * np.random.normal(0, 1, 
                                                               duration - fall_start - fall_duration)
        
        return modulation
    
    def _apply_multipath_effects(self, base_channel, activity_mod):
        """搴旂敤澶氬緞浼犳挱鏁堝簲"""
        # 鏃跺彉淇￠亾寤烘ā
        H_dynamic = np.zeros_like(base_channel, dtype=complex)
        
        for t in range(self.T):
            # 娲诲姩鐩稿叧鐨勮矾寰勫鐩婂彉鍖?
            path_gain_variation = 1.0 + activity_mod[t]
            
            # 澶氭櫘鍕掗绉绘晥搴?
            doppler_shift = self._compute_doppler_shift(activity_mod[t])
            
            # 搴旂敤鍒板悇瀛愯浇娉?
            for f in range(self.F):
                H_dynamic[t, f] = base_channel[t, f] * path_gain_variation * \
                                 np.exp(1j * doppler_shift * t)
        
        return H_dynamic
    
    def _add_environmental_noise(self, signal):
        """娣诲姞鐜鍣０鍜屽共鎵?""
        # 1. 楂樻柉鐧藉櫔澹?
        noise_power = self.noise_std ** 2
        noise = np.sqrt(noise_power/2) * (
            np.random.normal(0, 1, signal.shape) + 
            1j * np.random.normal(0, 1, signal.shape)
        )
        
        # 2. 棰戠巼閫夋嫨鎬ц“钀?
        fading = np.random.rayleigh(1.0, signal.shape)
        
        # 3. 鐩镐綅鍣０
        phase_noise = np.random.normal(0, 0.1, signal.shape)
        
        # 鍚堟垚鍣０淇″彿
        noisy_signal = signal * fading * np.exp(1j * phase_noise) + noise
        
        return noisy_signal
    
    def _extract_csi_features(self, complex_signal):
        """浠庡鏁颁俊鍙锋彁鍙朇SI鐗瑰緛"""
        # 骞呭害鐗瑰緛
        amplitude = np.abs(complex_signal)
        
        # 鐩镐綅鐗瑰緛锛堝睍寮€锛?
        phase = np.unwrap(np.angle(complex_signal), axis=1)
        
        # 缁勫悎鐗瑰緛
        features = np.concatenate([amplitude, phase], axis=1)
        
        # 鏍囧噯鍖?
        features = (features - np.mean(features, axis=0)) / np.std(features, axis=0)
        
        return features
\end{lstlisting}

\subsection{Enhanced妯″瀷璇︾粏瀹炵幇}
\label{subsec:enhanced_implementation}

\subsubsection{瀹屾暣妯″瀷瀹氫箟}
\texttt{src/models.py} 涓璄nhanced妯″瀷鐨勫畬鏁村疄鐜帮細

\begin{lstlisting}[language=Python,caption=Enhanced妯″瀷瀹屾暣瀹炵幇]
import torch
import torch.nn as nn
import torch.nn.functional as F

class SEModule(nn.Module):
    """Squeeze-and-Excitation妯″潡"""
    
    def __init__(self, channels, reduction=16):
        super(SEModule, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, t = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.expand_as(x)

class TemporalAttention(nn.Module):
    """鏃跺簭娉ㄦ剰鍔涙ā鍧?""
    
    def __init__(self, input_dim, hidden_dim=64):
        super(TemporalAttention, self).__init__()
        self.hidden_dim = hidden_dim
        
        self.query = nn.Linear(input_dim, hidden_dim)
        self.key = nn.Linear(input_dim, hidden_dim)
        self.value = nn.Linear(input_dim, hidden_dim)
        
        self.scale = hidden_dim ** -0.5
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x):
        # x: (batch, time, features)
        B, T, F = x.size()
        
        Q = self.query(x)  # (B, T, H)
        K = self.key(x)    # (B, T, H)
        V = self.value(x)  # (B, T, H)
        
        # 璁＄畻娉ㄦ剰鍔涙潈閲?
        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale
        attention_weights = F.softmax(attention_scores, dim=-1)
        attention_weights = self.dropout(attention_weights)
        
        # 搴旂敤娉ㄦ剰鍔?
        attended = torch.matmul(attention_weights, V)
        
        return attended

class EnhancedCSIModel(nn.Module):
    """Enhanced WiFi CSI HAR妯″瀷"""
    
    def __init__(self, input_shape, num_classes=4, hidden_dim=256):
        super(EnhancedCSIModel, self).__init__()
        
        T, F = input_shape
        self.input_shape = input_shape
        
        # 1. 鍗风Н鐗瑰緛鎻愬彇
        self.conv_layers = nn.Sequential(
            # 绗竴灞傚嵎绉?
            nn.Conv1d(F, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            
            # 绗簩灞傚嵎绉?
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            
            # 绗笁灞傚嵎绉?
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
        )
        
        # 2. SE娉ㄦ剰鍔涙ā鍧?
        self.se_module = SEModule(128, reduction=16)
        
        # 3. BiLSTM鏃跺簭寤烘ā
        self.bilstm = nn.LSTM(
            input_size=128,
            hidden_size=hidden_dim // 2,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=0.1
        )
        
        # 4. 鏃跺簭娉ㄦ剰鍔?
        self.temporal_attention = TemporalAttention(
            input_dim=hidden_dim,
            hidden_dim=64
        )
        
        # 5. 鍒嗙被鍣?
        self.classifier = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(32, num_classes)
        )
        
        # 鍒濆鍖栨潈閲?
        self._initialize_weights()
    
    def forward(self, x):
        # 杈撳叆: (batch, time, freq)
        batch_size, seq_len, n_features = x.size()
        
        # 1. 鍗风Н鐗瑰緛鎻愬彇
        # 杞疆涓?(batch, freq, time) for Conv1d
        x = x.transpose(1, 2)  # (batch, freq, time)
        conv_features = self.conv_layers(x)  # (batch, 128, time)
        
        # 2. SE娉ㄦ剰鍔?
        se_features = self.se_module(conv_features)  # (batch, 128, time)
        
        # 3. 杞崲涓篖STM杈撳叆鏍煎紡
        lstm_input = se_features.transpose(1, 2)  # (batch, time, 128)
        
        # 4. BiLSTM鏃跺簭寤烘ā
        lstm_output, (h_n, c_n) = self.bilstm(lstm_input)  # (batch, time, hidden_dim)
        
        # 5. 鏃跺簭娉ㄦ剰鍔?
        attention_output = self.temporal_attention(lstm_output)  # (batch, time, 64)
        
        # 6. 鍏ㄥ眬骞冲潎姹犲寲
        pooled = torch.mean(attention_output, dim=1)  # (batch, 64)
        
        # 7. 鍒嗙被杈撳嚭
        logits = self.classifier(pooled)  # (batch, num_classes)
        
        return logits
    
    def _initialize_weights(self):
        """鏉冮噸鍒濆鍖?""
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.LSTM):
                for name, param in m.named_parameters():
                    if 'weight_ih' in name:
                        nn.init.xavier_uniform_(param.data)
                    elif 'weight_hh' in name:
                        nn.init.orthogonal_(param.data)
                    elif 'bias' in name:
                        param.data.fill_(0)
\end{lstlisting}

\section{瀹為獙绠＄悊涓庣増鏈帶鍒秨
\label{sec:experiment_management}

\subsection{Git鍒嗘敮绠＄悊绛栫暐}
\label{subsec:git_strategy}

椤圭洰閲囩敤绯荤粺鍖栫殑Git鍒嗘敮绠＄悊绛栫暐纭繚瀹為獙鐨勫彲杩芥函鎬у拰鐗堟湰鎺у埗锛?

\begin{description}
\item[\texttt{master}] 涓诲垎鏀紝鍖呭惈绋冲畾鐨勫彂甯冪増鏈?
\item[\texttt{feat/enhanced-model-and-sweep}] 涓昏寮€鍙戝垎鏀紝鍖呭惈Enhanced妯″瀷鍜屽弬鏁版壂鎻忓疄楠?
\item[\texttt{results/exp-*}] 瀹為獙缁撴灉鍒嗘敮锛屼繚瀛樼壒瀹氬疄楠岀殑瀹屾暣缁撴灉
\end{description}

\subsection{瀹為獙璁板綍涓庡彲閲嶇幇鎬
\label{subsec:reproducibility}

\subsubsection{瀹為獙閰嶇疆绠＄悊}
鎵€鏈夊疄楠岄厤缃兘淇濆瓨涓篔SON鏍煎紡锛岀‘淇濆畬鍏ㄥ彲閲嶇幇锛?

\begin{lstlisting}[language=json,caption=瀹為獙閰嶇疆绀轰緥]
{
  "experiment_name": "D2_Enhanced_Hard_Seed0",
  "protocol": "D2",
  "model_config": {
    "name": "enhanced",
    "input_shape": [128, 52],
    "hidden_dim": 256,
    "num_classes": 4
  },
  "data_config": {
    "n_samples": 20000,
    "difficulty": "hard",
    "noise_std": 0.6,
    "class_overlap": 0.8,
    "gain_drift_std": 0.6,
    "sc_corr_rho": 0.5,
    "env_burst_rate": 0.2
  },
  "training_config": {
    "epochs": 100,
    "batch_size": 768,
    "learning_rate": 1e-3,
    "optimizer": "Adam",
    "scheduler": "CosineAnnealingLR",
    "early_stopping": {
      "metric": "macro_f1",
      "patience": 10
    },
    "regularization": {
      "logit_l2": 0.1,
      "dropout": 0.1
    }
  },
  "evaluation_config": {
    "metrics": ["macro_f1", "falling_f1", "ece", "brier_score"],
    "calibration": {
      "method": "temperature_scaling",
      "validation_split": 0.2
    }
  },
  "random_seed": 0,
  "timestamp": "2025-01-19T10:30:00Z",
  "git_commit": "26ea325a7b8c9d4e..."
}
\end{lstlisting}

\section{缁撴灉鍙鍖栦笌鍒嗘瀽宸ュ叿}
\label{sec:visualization}

\subsection{缁煎悎鎬ц兘鍒嗘瀽鍥捐〃}
\label{subsec:performance_visualization}

椤圭洰寮€鍙戜簡瀹屾暣鐨勫彲瑙嗗寲宸ュ叿閾撅紝鍖呮嫭锛?

\begin{enumerate}
\item \textbf{鎬ц兘鏉″舰鍥緘锛歕texttt{scripts/plot\_d1\_bars.py}
\item \textbf{閲嶅彔搴︽暎鐐瑰浘}锛歕texttt{scripts/plot\_d1\_overlap\_scatter.py}
\item \textbf{璺ㄥ煙鎬ц兘绠辩嚎鍥緘锛歕texttt{scripts/plot\_d3\_folds\_box.py}
\item \textbf{鏍囩鏁堢巼鏇茬嚎}锛歕texttt{scripts/plot\_d4\_label\_efficiency.py}
\item \textbf{鍙潬鎬ф洸绾縸锛歕texttt{scripts/plot\_reliability.py}
\item \textbf{PCA鐗瑰緛绌洪棿鍒嗘瀽}锛歕texttt{paper/figures/figure7\_pca\_analysis.py}
\end{enumerate}

\section{瀹為獙缁撹涓庤础鐚€荤粨}
\label{sec:conclusions}

\subsection{涓昏瀹為獙鍙戠幇}
\label{subsec:key_findings}

鏈疄楠岀爺绌剁殑涓昏鍙戠幇鍖呮嫭锛?

\begin{enumerate}
\item \textbf{鐗╃悊鎸囧鐢熸垚鐨勬湁鏁堟€锛氬悎鎴愭暟鎹兘澶熸湁鏁堟敮鎸佹ā鍨嬭缁冿紝閬垮厤浜嗚繃鎷熷悎鍒颁笉鐜板疄鐨勬暟鎹垎甯?
\item \textbf{Enhanced鏋舵瀯鐨勪紭瓒婃€锛歋E-Attention闆嗘垚璁捐瀹炵幇浜嗘渶浣崇殑鎬ц兘鍜岀ǔ瀹氭€у钩琛?
\item \textbf{璺ㄥ煙娉涘寲鐨勭獊鐮磢锛氶娆″疄鐜颁簡瀹岀編鐨凩OSO-LORO涓€鑷存€э紙83.0卤0.1\%锛?
\item \textbf{鏍囩鏁堢巼鐨勯潻鍛芥€ф彁鍗噠锛?0\%鏍囨敞鏁版嵁杈惧埌98.6\%鍏ㄧ洃鐫ｆ€ц兘
\item \textbf{鍙俊搴﹁瘎浼扮殑閲嶈鎬锛氭牎鍑嗗垎鏋愭彮绀轰簡妯″瀷缃俊搴︾殑璐ㄩ噺宸紓
\end{enumerate}

\subsection{鎶€鏈础鐚笌鍒涙柊}
\label{subsec:technical_contributions}

\begin{itemize}
\item \textbf{鐞嗚璐＄尞}锛氬缓绔嬩簡WiFi CSI HAR鐨勭墿鐞嗘寚瀵煎悎鎴愭暟鎹敓鎴愮悊璁烘鏋?
\item \textbf{鏂规硶鍒涙柊}锛氶娆＄郴缁熸€у湴搴旂敤Sim2Real杩佺Щ瀛︿範鍒癢iFi鎰熺煡棰嗗煙
\item \textbf{鏋舵瀯璁捐}锛氭彁鍑轰簡SE-Attention闆嗘垚鐨凟nhanced鏋舵瀯
\item \textbf{璇勪及鍗忚}锛氬缓绔嬩簡CDAE鍜孲TEA璇勪及鏍囧噯锛屽～琛ヤ簡棰嗗煙绌虹櫧
\item \textbf{宸ョ▼瀹炵幇}锛氬紑鍙戜簡瀹屾暣鐨勫疄楠岀鐞嗗拰鍙鍖栧伐鍏烽摼
\end{itemize}

\subsection{瀹為檯搴旂敤浠峰€紏
\label{subsec:practical_value}

\begin{description}
\item[鎴愭湰闄嶄綆] 80\%鐨勬爣娉ㄦ垚鏈檷浣庝娇WiFi鎰熺煡鎶€鏈洿鏄撲簬浜т笟鍖栭儴缃?
\item[娉涘寲鑳藉姏] 瀹岀編鐨勮法鍩熶竴鑷存€цВ鍐充簡瀹為檯閮ㄧ讲涓殑鐜閫傚簲闂
\item[閮ㄧ讲鏁堢巼] 鏍囧噯鍖栫殑璇勪及鍗忚鍔犻€熶簡妯″瀷鐨勫疄闄呭簲鐢ㄩ獙璇佽繃绋?
\item[鍙俊搴︿繚闅淽 鏍″噯鍒嗘瀽涓哄畨鍏ㄥ叧閿簲鐢ㄦ彁渚涗簡鍙潬鎬т繚璇?
\end{description}

\section{鏈珷灏忕粨}
\label{sec:chapter_summary}

鏈珷璇︾粏璁板綍浜哤iFi CSI浜轰綋娲诲姩璇嗗埆鐨勭墿鐞嗘寚瀵煎悎鎴愭暟鎹敓鎴愪笌鍙俊璇勪及妗嗘灦鐨勫畬鏁村疄楠岀爺绌惰繃绋嬨€傞€氳繃D2銆丆DAE鍜孲TEA涓変釜绯荤粺鎬ц瘎浼板崗璁紝楠岃瘉浜嗙墿鐞嗘寚瀵煎悎鎴愭暟鎹敓鎴愭柟娉曠殑鏈夋晥鎬э紝璇佹槑浜咵nhanced妯″瀷鏋舵瀯鐨勪紭瓒婃€э紝瀹炵幇浜嗚法鍩熸硾鍖栧拰鏍囩鏁堢巼鐨勫弻閲嶇獊鐮淬€?

瀹為獙缁撴灉涓嶄粎鍦ㄥ鏈眰闈㈡帹杩涗簡WiFi鎰熺煡棰嗗煙鐨勬柟娉曡杩涘睍锛屾洿鍦ㄥ伐绋嬪疄璺靛眰闈负WiFi鎰熺煡鎶€鏈殑浜т笟鍖栭儴缃叉彁渚涗簡鍙鐨勮В鍐虫柟妗堛€傜壒鍒槸20\%鏍囨敞鏁版嵁杈惧埌98.6\%鍏ㄧ洃鐫ｆ€ц兘鐨勭獊鐮达紝涓鸿祫婧愬彈闄愮幆澧冧笅鐨勯儴缃叉彁渚涗簡寮烘湁鍔涚殑鏀寔銆?

杩欎簺瀹為獙宸ヤ綔涓哄悗缁殑鐮旂┒鍜屽簲鐢ㄥ瀹氫簡鍧氬疄鐨勫熀纭€锛屽悓鏃跺缓绔嬩簡鍙噸鐜般€佸彲鎵╁睍鐨勫疄楠屾鏋讹紝涓洪鍩熷唴鐨勮繘涓€姝ョ爺绌舵彁渚涗簡鏈変环鍊肩殑宸ュ叿鍜屾柟娉曘€?

