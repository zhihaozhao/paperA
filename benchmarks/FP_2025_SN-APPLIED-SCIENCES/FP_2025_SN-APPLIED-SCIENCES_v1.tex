%% SN Applied Sciences LaTeX Template
%% Based on Springer guidelines

\documentclass[sn-basic]{sn-jnl}

% Required packages
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{array}
\usepackage{url}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document}

\title{Systematic Review of Autonomous Fruit-Picking Technologies: From Perception to Action in Agricultural Robotics}

\author{Zhihao Zhao\Email{zzhaoooooo@gmail.com}\Orcid{0000-0000-0000-0000}%
\and
Yanxiang Zhao\Email{author2@example.com}%
\and  
Nur Syazreen Ahmad\Email{syazreen@usm.my}\Orcid{0000-0001-7511-2910}}

\affil{School of Electrical and Electronic Engineering, Universiti Sains Malaysia, 14300 Nibong Tebal, Penang, Malaysia}

\abstract{\textbf{Background:} Agricultural sectors globally face critical challenges including labor shortages and escalating operational costs, driving the need for autonomous fruit-picking robotic solutions. Despite significant technological advances, comprehensive systematic reviews examining the integration of perception systems with motion control in agricultural robotics remain limited.

\textbf{Methods:} This systematic review follows PRISMA guidelines to analyze 137 peer-reviewed studies published between 2015 and 2024. We systematically searched Scopus, Web of Science, and ScienceDirect databases using predefined inclusion/exclusion criteria. We critically examined learning-based perception approaches (R-CNN and YOLO families) and motion planning algorithms, quantifying performance trade-offs across diverse orchard conditions.

\textbf{Results:} Deep learning models demonstrated substantial improvements in fruit detection capabilities, with YOLO series achieving 84-99\% detection accuracy and R-CNN family showing superior instance segmentation performance. Motion planning algorithms, including A*, Bi-RRT, and DDPG, exhibited success rates ranging from 58-92\% in field applications. Harvesting cycle times varied from 4-24 seconds across different fruits and environmental conditions. However, significant challenges persist in occlusion handling, multi-sensor fusion, and cost-effective scalability.

\textbf{Conclusions:} While substantial technological progress has been achieved in individual components, integration of perception-to-action pipelines remains a critical challenge. Future research priorities include developing neural architecture search methods, implementing adaptive fusion algorithms, and establishing standardized benchmarks to accelerate commercial deployment across diverse agricultural contexts.}

\keywords{Agricultural robotics, Computer vision, Deep learning, Motion planning, Systematic review, Autonomous systems}

\maketitle

% ... existing code ...

\end{document}