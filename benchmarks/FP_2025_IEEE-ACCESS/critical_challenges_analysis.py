#!/usr/bin/env python3
"""
æ‰¹åˆ¤æ€§æŒ‘æˆ˜åˆ†æè„šæœ¬ - Figure 10æ•°æ®å‡†å¤‡
åŸºäº24ç¯‡æŒ‘æˆ˜è¶‹åŠ¿è®ºæ–‡è¿›è¡Œæ·±åº¦æ‰¹åˆ¤æ€§åˆ†æ
é‡ç‚¹å…³æ³¨ï¼šç ”ç©¶é—®é¢˜ã€æ€§èƒ½å±€é™ã€æ¨¡å‹ç¼ºé™·ã€æ”¹è¿›æ–¹å‘
"""

import csv
import re
from collections import Counter, defaultdict

def extract_critical_challenges_data():
    """æå–æ‰¹åˆ¤æ€§æŒ‘æˆ˜å’Œç ”ç©¶å±€é™æ•°æ®"""
    try:
        with open('/workspace/benchmarks/docs/prisma_data.csv', 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        
        challenge_papers = []
        research_problems = defaultdict(list)
        performance_limitations = defaultdict(list)
        model_defects = defaultdict(list)
        future_gaps = defaultdict(list)
        
        print("=== æ‰¹åˆ¤æ€§æŒ‘æˆ˜åˆ†æ (Figure 10) ===")
        
        for i, line in enumerate(lines[1:], 1):
            if line.strip():
                parts = line.split(',')
                if len(parts) > 0 and parts[0].strip().lower() == 'y':
                    title = parts[2] if len(parts) > 2 else ''
                    year = parts[4] if len(parts) > 4 else ''
                    challenges = parts[15] if len(parts) > 15 else ''
                    abstract = parts[17] if len(parts) > 17 else ''
                    
                    title_lower = title.lower()
                    challenge_lower = challenges.lower()
                    abstract_lower = abstract.lower()
                    
                    # æ‰¹åˆ¤æ€§åˆ†æç›¸å…³è®ºæ–‡
                    is_critical_paper = any(keyword in title_lower + challenge_lower + abstract_lower for keyword in 
                                          ['challenge', 'problem', 'limitation', 'future', 'trend', 'review', 
                                           'survey', 'gap', 'barrier', 'constraint', 'failure', 'difficulty'])
                    
                    if is_critical_paper:
                        paper_data = {
                            'title': title,
                            'year': year,
                            'challenges': challenges,
                            'abstract': abstract[:500] + "..." if len(abstract) > 500 else abstract
                        }
                        challenge_papers.append(paper_data)
                        
                        # åˆ†æç ”ç©¶é—®é¢˜ç±»åˆ«
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['cost', 'expensive', 'economic', 'commercial', 'investment']):
                            research_problems['Economic-Viability'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['accuracy', 'precision', 'detection', 'error', 'false']):
                            performance_limitations['Detection-Accuracy'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['environment', 'weather', 'lighting', 'robust', 'variable']):
                            performance_limitations['Environmental-Robustness'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['speed', 'time', 'real-time', 'processing', 'latency']):
                            performance_limitations['Processing-Speed'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['generalization', 'transfer', 'adaptability', 'specific']):
                            model_defects['Limited-Generalization'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['occlusion', 'hidden', 'overlap', 'dense', 'foliage']):
                            model_defects['Occlusion-Handling'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['integration', 'coordination', 'fusion', 'system']):
                            future_gaps['System-Integration'].append(paper_data)
                        
                        if any(keyword in challenge_lower + abstract_lower for keyword in 
                               ['field', 'deployment', 'practical', 'commercial']):
                            future_gaps['Lab-to-Field-Gap'].append(paper_data)
        
        print(f"æ‰¹åˆ¤æ€§åˆ†æè®ºæ–‡æ€»æ•°: {len(challenge_papers)}")
        
        print(f"\nğŸš¨ æ ¸å¿ƒç ”ç©¶é—®é¢˜:")
        for problem, papers in research_problems.items():
            print(f"  {problem}: {len(papers)} papers")
            if papers:
                print(f"    ç¤ºä¾‹: {papers[0]['title'][:60]}...")
        
        print(f"\nâš¡ æ€§èƒ½å±€é™åˆ†æ:")
        for limitation, papers in performance_limitations.items():
            print(f"  {limitation}: {len(papers)} papers")
            if papers:
                print(f"    ç¤ºä¾‹: {papers[0]['title'][:60]}...")
        
        print(f"\nğŸ”§ æ¨¡å‹ç¼ºé™·åˆ†æ:")
        for defect, papers in model_defects.items():
            print(f"  {defect}: {len(papers)} papers")
            if papers:
                print(f"    ç¤ºä¾‹: {papers[0]['title'][:60]}...")
        
        print(f"\nğŸ”® æœªæ¥ç ”ç©¶ç¼ºå£:")
        for gap, papers in future_gaps.items():
            print(f"  {gap}: {len(papers)} papers")
            if papers:
                print(f"    ç¤ºä¾‹: {papers[0]['title'][:60]}...")
        
        # å¹´åº¦è¶‹åŠ¿ - é—®é¢˜æŒç»­æ€§åˆ†æ
        persistent_issues = analyze_persistent_issues(challenge_papers)
        
        # è¯†åˆ«æœªæˆç†Ÿä½†æ´»è·ƒçš„ç ”ç©¶æ–¹å‘
        emerging_directions = identify_emerging_directions(challenge_papers)
        
        return {
            'total_papers': len(challenge_papers),
            'research_problems': dict(research_problems),
            'performance_limitations': dict(performance_limitations),
            'model_defects': dict(model_defects),
            'future_gaps': dict(future_gaps),
            'persistent_issues': persistent_issues,
            'emerging_directions': emerging_directions,
            'sample_papers': challenge_papers[:10]
        }
        
    except Exception as e:
        print(f"æ‰¹åˆ¤æ€§åˆ†æé”™è¯¯: {e}")
        return None

def analyze_persistent_issues(papers):
    """åˆ†ææŒç»­æ€§é—®é¢˜ - å¤šå¹´æœªè§£å†³çš„æŒ‘æˆ˜"""
    issue_by_year = defaultdict(lambda: defaultdict(int))
    
    key_issues = ['cost', 'accuracy', 'environment', 'occlusion', 'commercial', 'field']
    
    for paper in papers:
        try:
            year = int(float(paper['year']))
            if 2015 <= year <= 2024:
                text = (paper['challenges'] + ' ' + paper['abstract']).lower()
                for issue in key_issues:
                    if issue in text:
                        issue_by_year[year][issue] += 1
        except:
            continue
    
    print(f"\nğŸ“Š æŒç»­æ€§é—®é¢˜åˆ†æ (2015-2024):")
    for issue in key_issues:
        years_mentioned = []
        for year in sorted(issue_by_year.keys()):
            if issue_by_year[year][issue] > 0:
                years_mentioned.append(year)
        if len(years_mentioned) >= 3:  # è‡³å°‘3å¹´æåŠçš„æŒç»­é—®é¢˜
            print(f"  {issue.title()}: æŒç»­ {len(years_mentioned)} å¹´ ({years_mentioned[0]}-{years_mentioned[-1]})")
    
    return dict(issue_by_year)

def identify_emerging_directions(papers):
    """è¯†åˆ«æ–°å…´ä½†æœªæˆç†Ÿçš„ç ”ç©¶æ–¹å‘"""
    emerging_keywords = [
        'multi-robot', 'swarm', 'distributed', 'federated',
        'explainable', 'interpretable', 'uncertainty', 
        'sim2real', 'digital twin', 'edge computing',
        'sustainability', 'carbon footprint', 'green',
        'human-robot', 'collaborative', 'safety'
    ]
    
    emerging_trends = defaultdict(list)
    
    for paper in papers:
        text = (paper['title'] + ' ' + paper['challenges'] + ' ' + paper['abstract']).lower()
        for keyword in emerging_keywords:
            if keyword in text:
                emerging_trends[keyword].append(paper)
    
    print(f"\nğŸš€ æ–°å…´ç ”ç©¶æ–¹å‘ (æ´»è·ƒä½†æœªæˆç†Ÿ):")
    for direction, papers_list in emerging_trends.items():
        if len(papers_list) >= 1:  # è‡³å°‘1ç¯‡è®ºæ–‡æåŠ
            print(f"  {direction.title()}: {len(papers_list)} papers")
            if papers_list:
                print(f"    æœ€æ–°: {papers_list[0]['title'][:50]}...")
    
    return dict(emerging_trends)

if __name__ == "__main__":
    results = extract_critical_challenges_data()