#!/usr/bin/env python3
"""
æå–prisma_data.csvä¸­çš„çœŸå®æ•°æ®
ä¸¥æ ¼ä½¿ç”¨çœŸå®æ•°æ®ï¼Œé›¶ç¼–é€ 
"""

import csv
import json
import re
from collections import defaultdict, Counter

def extract_real_prisma_data():
    """ä»prisma_data.csvæå–æ‰€æœ‰çœŸå®æ•°æ®"""
    
    print("ğŸ“Š ä»prisma_data.csvæå–çœŸå®æ•°æ®...")
    
    # è¯»å–prismaæ•°æ®
    papers = []
    bibtex_keys = []
    
    try:
        with open('../docs/prisma_data.csv', 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            headers = next(reader)  # è·³è¿‡æ ‡é¢˜è¡Œ
            
            print(f"ğŸ“‹ CSVåˆ—æ ‡é¢˜: {headers}")
            
            for row_num, row in enumerate(reader, 2):
                if len(row) >= 8:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                    paper_data = {
                        'row': row_num,
                        'relevant': row[0] if len(row) > 0 else '',
                        'database': row[1] if len(row) > 1 else '',
                        'title': row[2] if len(row) > 2 else '',
                        'citations': row[3] if len(row) > 3 else '',
                        'year': row[4] if len(row) > 4 else '',
                        'selected': row[5] if len(row) > 5 else '',
                        'journal': row[6] if len(row) > 6 else '',
                        'bibtex_cite': row[7] if len(row) > 7 else '',  # Håˆ—
                        'bibtex_entry': row[8] if len(row) > 8 else ''   # Iåˆ—
                    }
                    
                    # åªæ”¶é›†ç›¸å…³çš„è®ºæ–‡ (relevant = 'y')
                    if paper_data['relevant'].lower() == 'y':
                        papers.append(paper_data)
                        
                        # æå–bibtex key
                        if '\\cite{' in paper_data['bibtex_cite']:
                            match = re.search(r'\\cite\{([^}]+)\}', paper_data['bibtex_cite'])
                            if match:
                                bibtex_keys.append(match.group(1))
    
    except Exception as e:
        print(f"âŒ è¯»å–prisma_data.csvå¤±è´¥: {e}")
        return None, None
    
    print(f"âœ… æå–åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡")
    print(f"âœ… æå–åˆ° {len(bibtex_keys)} ä¸ªçœŸå®bibtexå¼•ç”¨")
    
    return papers, bibtex_keys

def analyze_vision_algorithms(papers):
    """åˆ†æè§†è§‰ç®—æ³•è®ºæ–‡"""
    
    print("\nğŸ” åˆ†æè§†è§‰ç®—æ³•è®ºæ–‡...")
    
    vision_keywords = [
        'vision', 'yolo', 'rcnn', 'r-cnn', 'cnn', 'deep', 'detection', 
        'recognition', 'segmentation', 'mask', 'faster', 'object detection',
        'computer vision', 'image', 'visual', 'neural network'
    ]
    
    vision_papers = []
    algorithm_families = defaultdict(list)
    
    for paper in papers:
        title_lower = paper['title'].lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è§†è§‰ç›¸å…³è®ºæ–‡
        is_vision = any(keyword in title_lower for keyword in vision_keywords)
        
        if is_vision:
            vision_papers.append(paper)
            
            # åˆ†ç±»ç®—æ³•å®¶æ—
            if any(word in title_lower for word in ['yolo']):
                algorithm_families['YOLO'].append(paper)
            elif any(word in title_lower for word in ['rcnn', 'r-cnn', 'mask']):
                algorithm_families['R-CNN'].append(paper)
            elif any(word in title_lower for word in ['deep', 'cnn', 'neural']):
                algorithm_families['Deep Learning'].append(paper)
            elif any(word in title_lower for word in ['vision', 'visual', 'image']):
                algorithm_families['Traditional Vision'].append(paper)
            else:
                algorithm_families['Other'].append(paper)
    
    print(f"âœ… æ‰¾åˆ° {len(vision_papers)} ç¯‡è§†è§‰ç®—æ³•è®ºæ–‡")
    for family, papers_list in algorithm_families.items():
        print(f"   - {family}: {len(papers_list)} ç¯‡")
    
    return vision_papers, algorithm_families

def analyze_robotics_papers(papers):
    """åˆ†ææœºå™¨äººè®ºæ–‡"""
    
    print("\nğŸ¤– åˆ†ææœºå™¨äººè®ºæ–‡...")
    
    robotics_keywords = [
        'robot', 'robotic', 'harvesting', 'picking', 'gripper', 'manipulator',
        'autonomous', 'automation', 'control', 'motion', 'path planning',
        'end effector', 'mechanical'
    ]
    
    robotics_papers = []
    control_methods = defaultdict(list)
    
    for paper in papers:
        title_lower = paper['title'].lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœºå™¨äººç›¸å…³è®ºæ–‡
        is_robotics = any(keyword in title_lower for keyword in robotics_keywords)
        
        if is_robotics:
            robotics_papers.append(paper)
            
            # åˆ†ç±»æ§åˆ¶æ–¹æ³•
            if any(word in title_lower for word in ['path', 'planning', 'motion']):
                control_methods['Path Planning'].append(paper)
            elif any(word in title_lower for word in ['control', 'pid', 'feedback']):
                control_methods['Control Systems'].append(paper)
            elif any(word in title_lower for word in ['gripper', 'end effector', 'manipulator']):
                control_methods['End Effectors'].append(paper)
            elif any(word in title_lower for word in ['autonomous', 'automation']):
                control_methods['Autonomous Systems'].append(paper)
            else:
                control_methods['General Robotics'].append(paper)
    
    print(f"âœ… æ‰¾åˆ° {len(robotics_papers)} ç¯‡æœºå™¨äººè®ºæ–‡")
    for method, papers_list in control_methods.items():
        print(f"   - {method}: {len(papers_list)} ç¯‡")
    
    return robotics_papers, control_methods

def analyze_critical_trends(papers):
    """åˆ†æå…³é”®è¶‹åŠ¿"""
    
    print("\nğŸ“ˆ åˆ†æå…³é”®è¶‹åŠ¿...")
    
    # æŒ‰å¹´ä»½åˆ†æ
    year_distribution = Counter()
    citation_trends = []
    
    for paper in papers:
        year = paper['year']
        if year and year.isdigit():
            year_int = int(year)
            year_distribution[year_int] += 1
            
            # å¼•ç”¨æ•°åˆ†æ
            citations = paper['citations']
            if citations and citations.isdigit():
                citation_trends.append({
                    'year': year_int,
                    'citations': int(citations),
                    'title': paper['title']
                })
    
    # æ’åºè·å–é«˜å¼•ç”¨è®ºæ–‡
    citation_trends.sort(key=lambda x: x['citations'], reverse=True)
    top_cited = citation_trends[:20]  # å‰20ç¯‡é«˜å¼•ç”¨è®ºæ–‡
    
    print(f"âœ… å¹´ä»½åˆ†å¸ƒ: {dict(year_distribution)}")
    print(f"âœ… å‰20ç¯‡é«˜å¼•ç”¨è®ºæ–‡å·²è¯†åˆ«")
    
    return year_distribution, top_cited

def generate_real_figure_data():
    """ç”ŸæˆçœŸå®çš„å›¾è¡¨æ•°æ®"""
    
    print("\nğŸ“Š ç”ŸæˆçœŸå®å›¾è¡¨æ•°æ®...")
    
    # æå–çœŸå®æ•°æ®
    papers, bibtex_keys = extract_real_prisma_data()
    
    if not papers:
        print("âŒ æ— æ³•æå–æ•°æ®")
        return False
    
    # åˆ†æå„ç±»è®ºæ–‡
    vision_papers, algorithm_families = analyze_vision_algorithms(papers)
    robotics_papers, control_methods = analyze_robotics_papers(papers)
    year_distribution, top_cited = analyze_critical_trends(papers)
    
    # ä¿å­˜Figure 4æ•°æ® (è§†è§‰ç®—æ³•)
    figure4_data = {
        'total_vision_papers': len(vision_papers),
        'algorithm_families': {family: len(papers_list) for family, papers_list in algorithm_families.items()},
        'detailed_papers': []
    }
    
    for family, papers_list in algorithm_families.items():
        for paper in papers_list[:5]:  # æ¯ä¸ªå®¶æ—å–å‰5ç¯‡
            bibtex_key = ''
            if '\\cite{' in paper['bibtex_cite']:
                match = re.search(r'\\cite\{([^}]+)\}', paper['bibtex_cite'])
                if match:
                    bibtex_key = match.group(1)
            
            figure4_data['detailed_papers'].append({
                'family': family,
                'title': paper['title'],
                'year': paper['year'],
                'citations': paper['citations'],
                'bibtex_key': bibtex_key
            })
    
    # ä¿å­˜Figure 9æ•°æ® (æœºå™¨äººæ§åˆ¶)
    figure9_data = {
        'total_robotics_papers': len(robotics_papers),
        'control_methods': {method: len(papers_list) for method, papers_list in control_methods.items()},
        'detailed_papers': []
    }
    
    for method, papers_list in control_methods.items():
        for paper in papers_list[:5]:  # æ¯ä¸ªæ–¹æ³•å–å‰5ç¯‡
            bibtex_key = ''
            if '\\cite{' in paper['bibtex_cite']:
                match = re.search(r'\\cite\{([^}]+)\}', paper['bibtex_cite'])
                if match:
                    bibtex_key = match.group(1)
            
            figure9_data['detailed_papers'].append({
                'method': method,
                'title': paper['title'],
                'year': paper['year'],
                'citations': paper['citations'],
                'bibtex_key': bibtex_key
            })
    
    # ä¿å­˜Figure 10æ•°æ® (å…³é”®è¶‹åŠ¿)
    figure10_data = {
        'year_distribution': dict(year_distribution),
        'top_cited_papers': []
    }
    
    for paper_info in top_cited[:20]:
        # æ‰¾åˆ°å¯¹åº”çš„å®Œæ•´è®ºæ–‡ä¿¡æ¯
        for paper in papers:
            if paper['title'] == paper_info['title']:
                bibtex_key = ''
                if '\\cite{' in paper['bibtex_cite']:
                    match = re.search(r'\\cite\{([^}]+)\}', paper['bibtex_cite'])
                    if match:
                        bibtex_key = match.group(1)
                
                figure10_data['top_cited_papers'].append({
                    'title': paper['title'],
                    'year': paper['year'],
                    'citations': paper['citations'],
                    'bibtex_key': bibtex_key
                })
                break
    
    # ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶
    with open('REAL_FIGURE4_DATA.json', 'w', encoding='utf-8') as f:
        json.dump(figure4_data, f, indent=2, ensure_ascii=False)
    
    with open('REAL_FIGURE9_DATA.json', 'w', encoding='utf-8') as f:
        json.dump(figure9_data, f, indent=2, ensure_ascii=False)
    
    with open('REAL_FIGURE10_DATA.json', 'w', encoding='utf-8') as f:
        json.dump(figure10_data, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜æ‰€æœ‰çœŸå®bibtexå¼•ç”¨
    with open('REAL_BIBTEX_KEYS.json', 'w', encoding='utf-8') as f:
        json.dump(bibtex_keys, f, indent=2, ensure_ascii=False)
    
    print("âœ… çœŸå®æ•°æ®å·²ä¿å­˜åˆ°JSONæ–‡ä»¶")
    print(f"ğŸ“„ REAL_FIGURE4_DATA.json - {len(vision_papers)}ç¯‡è§†è§‰è®ºæ–‡")
    print(f"ğŸ“„ REAL_FIGURE9_DATA.json - {len(robotics_papers)}ç¯‡æœºå™¨äººè®ºæ–‡") 
    print(f"ğŸ“„ REAL_FIGURE10_DATA.json - {len(top_cited)}ç¯‡é«˜å¼•ç”¨è®ºæ–‡")
    print(f"ğŸ“„ REAL_BIBTEX_KEYS.json - {len(bibtex_keys)}ä¸ªçœŸå®å¼•ç”¨")
    
    return True

if __name__ == "__main__":
    print("ğŸš¨ æå–prisma_data.csvä¸­çš„çœŸå®æ•°æ®")
    print("ğŸ”’ ä¸¥æ ¼ä½¿ç”¨çœŸå®æ•°æ®ï¼Œé›¶ç¼–é€ ")
    
    success = generate_real_figure_data()
    
    if success:
        print("\nâœ… çœŸå®æ•°æ®æå–å®Œæˆï¼")
        print("ğŸ“Š æ‰€æœ‰æ•°æ®æ¥è‡ªprisma_data.csv")
        print("ğŸ”’ é›¶ç¼–é€ ï¼Œ100%çœŸå®å¯éªŒè¯")
    else:
        print("\nâŒ æ•°æ®æå–å¤±è´¥ï¼")