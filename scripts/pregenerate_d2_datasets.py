#!/usr/bin/env python3
"""
D2å®éªŒä¸“ç”¨æ•°æ®é›†é¢„ç”Ÿæˆè„šæœ¬
æ ¹æ®å®é™…sweepé…ç½®é¢„ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„æ•°æ®é›†
"""

import json
import sys
import os
import itertools
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data_synth import SynthCSIDataset


def load_sweep_spec(spec_file):
    """åŠ è½½sweepé…ç½®æ–‡ä»¶"""
    try:
        with open(spec_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {spec_file}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        return None


def generate_param_combinations(spec):
    """ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ"""
    fixed = spec.get("fixed", {})
    grid = spec.get("grid", {})
    seeds = spec.get("seeds", [0])
    
    # ç”Ÿæˆç½‘æ ¼æœç´¢ç»„åˆ
    if not grid:
        # æ²¡æœ‰ç½‘æ ¼å‚æ•°ï¼Œåªæœ‰fixedå‚æ•°
        grid_combinations = [{}]
    else:
        keys = sorted(grid.keys())
        values = [grid[k] if isinstance(grid[k], (list, tuple)) else [grid[k]] for k in keys]
        grid_combinations = [dict(zip(keys, combo)) for combo in itertools.product(*values)]
    
    # æ¯ä¸ªç½‘æ ¼ç»„åˆ Ã— æ¯ä¸ªç§å­
    all_combinations = []
    for seed in seeds:
        for grid_combo in grid_combinations:
            # åˆå¹¶fixedå‚æ•°å’Œgridå‚æ•°
            params = {**fixed}
            params.update(grid_combo)
            params['seed'] = seed
            all_combinations.append(params)
    
    return all_combinations


def pregenerate_datasets_from_spec(spec_file, cache_dir="cache/synth_data", dry_run=False):
    """æ ¹æ®é…ç½®æ–‡ä»¶é¢„ç”Ÿæˆæ‰€æœ‰æ•°æ®é›†"""
    
    print(f"ğŸ”§ D2å®éªŒæ•°æ®é›†é¢„ç”Ÿæˆå·¥å…·")
    print(f"é…ç½®æ–‡ä»¶: {spec_file}")
    print(f"ç¼“å­˜ç›®å½•: {cache_dir}")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    spec = load_sweep_spec(spec_file)
    if not spec:
        return False
    
    # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
    combinations = generate_param_combinations(spec)
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  ç§å­æ•°: {len(spec.get('seeds', [0]))}")
    print(f"  ç½‘æ ¼å‚æ•°: {len(spec.get('grid', {}))}")
    print(f"  æ€»ç»„åˆæ•°: {len(combinations)}")
    print(f"  ä¼°è®¡æ¯ä¸ªè€—æ—¶: ~2åˆ†é’Ÿ")
    print(f"  é¢„è®¡æ€»è€—æ—¶: ~{len(combinations) * 2:.0f}åˆ†é’Ÿ ({len(combinations) * 2 / 60:.1f}å°æ—¶)")
    print()
    
    if dry_run:
        print("ğŸ” DRY RUN - é¢„è§ˆå‰10ä¸ªç»„åˆ:")
        for i, params in enumerate(combinations[:10]):
            print(f"  {i+1:3d}: {params}")
        if len(combinations) > 10:
            print(f"  ... è¿˜æœ‰ {len(combinations) - 10} ä¸ªç»„åˆ")
        return True
    
    # ç¡®è®¤ç»§ç»­
    response = input(f"ç¡®è®¤é¢„ç”Ÿæˆ {len(combinations)} ä¸ªæ•°æ®é›†? (y/N): ").strip().lower()
    if response not in ['y', 'yes']:
        print("âŒ å–æ¶ˆé¢„ç”Ÿæˆ")
        return False
    
    # å¼€å§‹é¢„ç”Ÿæˆ
    start_time = time.time()
    success_count = 0
    failed_combinations = []
    
    for i, params in enumerate(combinations, 1):
        print(f"\n[{i}/{len(combinations)}] é¢„ç”Ÿæˆæ•°æ®é›†...")
        
        # æå–SynthCSIDatasetéœ€è¦çš„å‚æ•°
        dataset_params = {
            'n': params.get('n_samples', 20000),
            'T': params.get('T', 128),
            'F': params.get('F', 30),
            'difficulty': params.get('difficulty', 'mid'),
            'seed': params.get('seed', 0),
            'sc_corr_rho': params.get('sc_corr_rho', None),
            'env_burst_rate': params.get('env_burst_rate', 0.0),
            'gain_drift_std': params.get('gain_drift_std', 0.0),
            'class_overlap': params.get('class_overlap', 0.0),
            'label_noise_prob': params.get('label_noise_prob', 0.0),
            'num_classes': params.get('num_classes', 8),
            'cache_dir': cache_dir
        }
        
        print(f"  å‚æ•°: n={dataset_params['n']}, seed={dataset_params['seed']}, "
              f"T={dataset_params['T']}, F={dataset_params['F']}, "
              f"difficulty={dataset_params['difficulty']}")
        
        iter_start = time.time()
        try:
            # ç”Ÿæˆæ•°æ®é›†ï¼ˆä¼šè‡ªåŠ¨å¤„ç†ç¼“å­˜ï¼‰
            dataset = SynthCSIDataset(**dataset_params)
            iter_time = time.time() - iter_start
            success_count += 1
            
            status = "ç”Ÿæˆ+ç¼“å­˜" if iter_time > 5 else "ç¼“å­˜å‘½ä¸­"
            print(f"  âœ… å®Œæˆ ({iter_time:.1f}ç§’, {status})")
            
        except Exception as e:
            iter_time = time.time() - iter_start
            print(f"  âŒ å¤±è´¥: {e} ({iter_time:.1f}ç§’)")
            failed_combinations.append((i, params, str(e)))
    
    # ç»Ÿè®¡ç»“æœ
    total_time = time.time() - start_time
    print(f"\n{'='*60}")
    print(f"ğŸ¯ é¢„ç”Ÿæˆå®Œæˆ!")
    print(f"  æˆåŠŸ: {success_count}/{len(combinations)}")
    print(f"  å¤±è´¥: {len(failed_combinations)}")
    print(f"  æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    print(f"  å¹³å‡æ¯ä¸ª: {total_time/len(combinations):.1f}ç§’")
    
    if failed_combinations:
        print(f"\nâŒ å¤±è´¥çš„ç»„åˆ:")
        for idx, params, error in failed_combinations[:5]:
            print(f"  {idx}: {params}")
            print(f"      é”™è¯¯: {error}")
        if len(failed_combinations) > 5:
            print(f"  ... è¿˜æœ‰ {len(failed_combinations) - 5} ä¸ªå¤±è´¥")
    
    # æ£€æŸ¥ç¼“å­˜ç›®å½•
    if os.path.exists(cache_dir):
        cache_files = [f for f in os.listdir(cache_dir) if f.endswith('.pkl')]
        total_size_mb = sum(os.path.getsize(os.path.join(cache_dir, f)) for f in cache_files) / (1024*1024)
        print(f"\nğŸ“ ç¼“å­˜ç»Ÿè®¡:")
        print(f"  ç¼“å­˜æ–‡ä»¶æ•°: {len(cache_files)}")
        print(f"  æ€»å¤§å°: {total_size_mb:.1f}MB")
        print(f"  ä½ç½®: {cache_dir}")
    
    return len(failed_combinations) == 0


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="D2å®éªŒæ•°æ®é›†é¢„ç”Ÿæˆå·¥å…·")
    parser.add_argument("--spec", type=str, default="scripts/d2_spec.json",
                       help="Sweepé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--cache-dir", type=str, default="cache/synth_data",
                       help="ç¼“å­˜ç›®å½•")
    parser.add_argument("--dry-run", action="store_true",
                       help="åªé¢„è§ˆï¼Œä¸å®é™…ç”Ÿæˆ")
    
    args = parser.parse_args()
    
    success = pregenerate_datasets_from_spec(
        spec_file=args.spec,
        cache_dir=args.cache_dir,
        dry_run=args.dry_run
    )
    
    if not success:
        sys.exit(1)
    
    print(f"\nâœ… ç°åœ¨è¿è¡Œæ‚¨çš„sweepå®éªŒå°†äº«å—ç§’çº§æ•°æ®åŠ è½½ï¼")
    print(f"å‘½ä»¤: python scripts/run_sweep_from_json.py --spec {args.spec} --resume")


if __name__ == "__main__":
    main()