#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„Sim2Realå®éªŒè®¾è®¡

ä¿æŒç°æœ‰æ¨¡å‹æ¶æ„ä¸å˜ï¼Œä¸“æ³¨äºä½¿ç”¨benchmarkçš„çœŸå®æ•°æ®æ¥éªŒè¯ï¼š
1. ç‰©ç†å¼•å¯¼åˆæˆæ•°æ®çš„æœ‰æ•ˆæ€§
2. Sim2Realè·¨åŸŸæ³›åŒ–èƒ½åŠ›
3. å°‘æ ·æœ¬å­¦ä¹ æ•ˆç‡
4. ç°æœ‰æ¨¡å‹çš„çœŸå®ä¸–ç•Œæ€§èƒ½

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-01-16
"""

import sys
import torch
import numpy as np
import json
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT / "src"))

from src.train_eval import build_model, train_one_epoch, eval_model
from src.data_synth import get_synth_loaders


class OptimizedSim2RealExperiments:
    """ä¼˜åŒ–çš„Sim2Realå®éªŒç®¡ç†å™¨"""
    
    def __init__(self, output_dir="results/sim2real"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç°æœ‰æ¨¡å‹åˆ—è¡¨ (ä¿æŒä¸å˜)
        self.our_models = ["enhanced", "cnn", "bilstm", "conformer_lite"]
        
        # é€‰æ‹©æ€§ä½¿ç”¨çš„benchmarkå‚è€ƒ
        self.reference_models = ["BiLSTM"]  # åªé€‰æ‹©1-2ä¸ªä½œä¸ºå‚è€ƒ
        
        # æ”¯æŒçš„çœŸå®æ•°æ®é›†
        self.real_datasets = ["UT_HAR", "NTU_Fi_HAR"]
    
    def experiment_1_baseline_establishment(self, dataset_name="UT_HAR"):
        """
        å®éªŒ1: å»ºç«‹çœŸå®æ•°æ®åŸºçº¿
        ç›®æ ‡: äº†è§£æˆ‘ä»¬çš„æ¨¡å‹åœ¨çœŸå®æ•°æ®ä¸Šçš„æ€§èƒ½æ°´å¹³
        """
        print(f"ğŸ¯ å®éªŒ1: {dataset_name} åŸºçº¿å»ºç«‹")
        
        # åŠ è½½çœŸå®æ•°æ®
        from docs.Optimized_Benchmark_Integration_Plan import create_sim2real_experiment
        
        try:
            exp_data = create_sim2real_experiment(dataset_name)
            real_train_loader, real_test_loader = exp_data["real"]
            metadata = exp_data["metadata"]
            
            results = {}
            
            # åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•æˆ‘ä»¬çš„æ‰€æœ‰æ¨¡å‹
            for model_name in self.our_models:
                print(f"ğŸ”„ æµ‹è¯•æ¨¡å‹: {model_name}")
                
                # æ„å»ºæ¨¡å‹
                model = build_model(
                    model_name, 
                    F=metadata["F"], 
                    num_classes=metadata["num_classes"],
                    T=metadata["T"]
                )
                
                # ç®€å•è®­ç»ƒ (å°è§„æ¨¡ï¼Œåªæ˜¯ä¸ºäº†è·å¾—åŸºçº¿æ€§èƒ½)
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                model = model.to(device)
                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
                criterion = torch.nn.CrossEntropyLoss()
                
                # è®­ç»ƒå‡ ä¸ªepochè·å¾—åŸºçº¿
                for epoch in range(10):  # å°‘é‡epochï¼Œåªæ˜¯ä¸ºäº†åŸºçº¿
                    train_loss = train_one_epoch(model, real_train_loader, optimizer, criterion, device)
                
                # è¯„ä¼°æ€§èƒ½
                eval_results = eval_model(model, real_test_loader, device)
                
                results[model_name] = {
                    "macro_f1": eval_results["macro_f1"],
                    "accuracy": eval_results.get("accuracy", 0),
                    "ece": eval_results.get("ece", 0),
                    "params": sum(p.numel() for p in model.parameters())
                }
                
                print(f"  {model_name}: F1={eval_results['macro_f1']:.3f}")
            
            # ä¿å­˜ç»“æœ
            result_file = self.output_dir / f"baseline_{dataset_name}.json"
            with open(result_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"âœ… åŸºçº¿ç»“æœå·²ä¿å­˜: {result_file}")
            return results
            
        except Exception as e:
            print(f"âŒ å®éªŒ1å¤±è´¥: {e}")
            print(f"è·³è¿‡å®éªŒ1ï¼Œå¯èƒ½æ˜¯æ•°æ®é›† {dataset_name} æœªä¸‹è½½")
            return {}
    
    def experiment_2_sim2real_core(self, dataset_name="UT_HAR"):
        """
        å®éªŒ2: æ ¸å¿ƒSim2RealéªŒè¯
        ç›®æ ‡: éªŒè¯åˆæˆæ•°æ®è®­ç»ƒçš„æ¨¡å‹åœ¨çœŸå®æ•°æ®ä¸Šçš„è¡¨ç°
        """
        print(f"ğŸ¯ å®éªŒ2: {dataset_name} Sim2Realæ ¸å¿ƒéªŒè¯")
        
        try:
            from docs.Optimized_Benchmark_Integration_Plan import create_sim2real_experiment
            exp_data = create_sim2real_experiment(dataset_name)
            
            synth_train_loader, synth_test_loader = exp_data["synthetic"]
            real_train_loader, real_test_loader = exp_data["real"]
            metadata = exp_data["metadata"]
            
            results = {}
            
            for model_name in self.our_models:
                print(f"ğŸ”„ Sim2Realæµ‹è¯•: {model_name}")
                
                # 1. åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒ
                model = build_model(
                    model_name,
                    F=metadata["F"],
                    num_classes=metadata["num_classes"], 
                    T=metadata["T"]
                )
                
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                model = model.to(device)
                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
                criterion = torch.nn.CrossEntropyLoss()
                
                # åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒ
                print("  ğŸ“Š åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒ...")
                for epoch in range(20):  # åˆæˆæ•°æ®ä¸Šå……åˆ†è®­ç»ƒ
                    train_loss = train_one_epoch(model, synth_train_loader, optimizer, criterion, device)
                
                # 2. åœ¨åˆæˆæ•°æ®ä¸Šè¯„ä¼° (å†…éƒ¨éªŒè¯)
                synth_results = eval_model(model, synth_test_loader, device)
                
                # 3. åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯• (è·¨åŸŸéªŒè¯)
                print("  ğŸŒ åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•...")
                real_results = eval_model(model, real_test_loader, device)
                
                # è®¡ç®—Sim2Realæ¯”ç‡
                sim2real_ratio = real_results["macro_f1"] / max(synth_results["macro_f1"], 0.001)
                
                results[model_name] = {
                    "synthetic_f1": synth_results["macro_f1"],
                    "real_f1": real_results["macro_f1"],
                    "sim2real_ratio": sim2real_ratio,
                    "synthetic_ece": synth_results.get("ece", 0),
                    "real_ece": real_results.get("ece", 0)
                }
                
                print(f"  {model_name}: åˆæˆF1={synth_results['macro_f1']:.3f}, "
                      f"çœŸå®F1={real_results['macro_f1']:.3f}, æ¯”ç‡={sim2real_ratio:.3f}")
            
            # ä¿å­˜ç»“æœ
            result_file = self.output_dir / f"sim2real_core_{dataset_name}.json"
            with open(result_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"âœ… Sim2Realç»“æœå·²ä¿å­˜: {result_file}")
            return results
            
        except Exception as e:
            print(f"âŒ å®éªŒ2å¤±è´¥: {e}")
            return {}
    
    def experiment_3_few_shot_learning(self, dataset_name="UT_HAR", ratios=[0.05, 0.1, 0.2, 0.5]):
        """
        å®éªŒ3: å°‘æ ·æœ¬å­¦ä¹ æ•ˆç‡
        ç›®æ ‡: è¯„ä¼°ç”¨å°‘é‡çœŸå®æ•°æ®å¾®è°ƒåˆæˆæ¨¡å‹çš„æ•ˆæœ
        """
        print(f"ğŸ¯ å®éªŒ3: {dataset_name} å°‘æ ·æœ¬å­¦ä¹ ")
        
        try:
            from docs.Optimized_Benchmark_Integration_Plan import create_sim2real_experiment
            exp_data = create_sim2real_experiment(dataset_name)
            
            synth_train_loader, synth_test_loader = exp_data["synthetic"]
            real_train_loader, real_test_loader = exp_data["real"]
            metadata = exp_data["metadata"]
            adapter = exp_data["adapter"]
            real_data = exp_data["real_data"]
            
            results = {}
            
            # åªæµ‹è¯•æˆ‘ä»¬æœ€å¥½çš„æ¨¡å‹ (enhanced)
            model_name = "enhanced"
            print(f"ğŸ”„ å°‘æ ·æœ¬å­¦ä¹ æµ‹è¯•: {model_name}")
            
            results[model_name] = {}
            
            for ratio in ratios:
                print(f"  ğŸ“Š æµ‹è¯•æ¯”ä¾‹: {ratio*100:.1f}%")
                
                # åˆ›å»ºå°‘æ ·æœ¬æ•°æ®
                few_shot_loader = adapter.create_few_shot_loader(real_data, ratio)
                
                # 1. å…ˆåœ¨åˆæˆæ•°æ®ä¸Šé¢„è®­ç»ƒ
                model = build_model(
                    model_name,
                    F=metadata["F"],
                    num_classes=metadata["num_classes"],
                    T=metadata["T"]  
                )
                
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                model = model.to(device)
                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
                criterion = torch.nn.CrossEntropyLoss()
                
                # åˆæˆæ•°æ®é¢„è®­ç»ƒ
                for epoch in range(15):
                    train_loss = train_one_epoch(model, synth_train_loader, optimizer, criterion, device)
                
                # 2. å°‘æ ·æœ¬å¾®è°ƒ
                optimizer_ft = torch.optim.Adam(model.parameters(), lr=0.0001)  # æ›´å°çš„å­¦ä¹ ç‡
                
                for epoch in range(10):  # å°‘é‡epoché¿å…è¿‡æ‹Ÿåˆ
                    train_loss = train_one_epoch(model, few_shot_loader, optimizer_ft, criterion, device)
                
                # 3. åœ¨çœŸå®æµ‹è¯•é›†ä¸Šè¯„ä¼°
                test_results = eval_model(model, real_test_loader, device)
                
                results[model_name][f"{ratio*100:.1f}%"] = {
                    "macro_f1": test_results["macro_f1"],
                    "ece": test_results.get("ece", 0),
                    "sample_count": len(few_shot_loader.dataset)
                }
                
                print(f"    {ratio*100:.1f}%æ•°æ®: F1={test_results['macro_f1']:.3f}, "
                      f"æ ·æœ¬æ•°={len(few_shot_loader.dataset)}")
            
            # ä¿å­˜ç»“æœ
            result_file = self.output_dir / f"few_shot_{dataset_name}.json"
            with open(result_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"âœ… å°‘æ ·æœ¬å­¦ä¹ ç»“æœå·²ä¿å­˜: {result_file}")
            return results
            
        except Exception as e:
            print(f"âŒ å®éªŒ3å¤±è´¥: {e}")
            return {}
    
    def experiment_4_domain_gap_analysis(self, dataset_name="UT_HAR"):
        """
        å®éªŒ4: åŸŸå·®è·åˆ†æ
        ç›®æ ‡: åˆ†æåˆæˆæ•°æ®ä¸çœŸå®æ•°æ®çš„å·®è·ç‰¹å¾
        """
        print(f"ğŸ¯ å®éªŒ4: {dataset_name} åŸŸå·®è·åˆ†æ")
        
        try:
            from docs.Optimized_Benchmark_Integration_Plan import create_sim2real_experiment
            exp_data = create_sim2real_experiment(dataset_name)
            
            synth_train_loader, synth_test_loader = exp_data["synthetic"]
            real_train_loader, real_test_loader = exp_data["real"]
            metadata = exp_data["metadata"]
            
            # ä½¿ç”¨æœ€å¥½çš„æ¨¡å‹è¿›è¡Œåˆ†æ
            model_name = "enhanced"
            print(f"ğŸ”„ åŸŸå·®è·åˆ†æ: {model_name}")
            
            results = {}
            
            # 1. çœŸå®â†’åˆæˆæ–¹å‘
            print("  ğŸ“Š çœŸå®æ•°æ®è®­ç»ƒ â†’ åˆæˆæ•°æ®æµ‹è¯•")
            model_r2s = build_model(
                model_name,
                F=metadata["F"], 
                num_classes=metadata["num_classes"],
                T=metadata["T"]
            )
            
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model_r2s = model_r2s.to(device)
            optimizer = torch.optim.Adam(model_r2s.parameters(), lr=0.001)
            criterion = torch.nn.CrossEntropyLoss()
            
            # åœ¨çœŸå®æ•°æ®ä¸Šè®­ç»ƒ
            for epoch in range(15):
                train_loss = train_one_epoch(model_r2s, real_train_loader, optimizer, criterion, device)
            
            # åœ¨çœŸå®æ•°æ®æµ‹è¯•é›†ä¸Šè¯„ä¼° (å†…åŸŸ)
            real_real_results = eval_model(model_r2s, real_test_loader, device)
            
            # åœ¨åˆæˆæ•°æ®ä¸Šæµ‹è¯• (è·¨åŸŸ)
            real_synth_results = eval_model(model_r2s, synth_test_loader, device)
            
            # 2. åˆæˆâ†’çœŸå®æ–¹å‘ (å‰é¢å®éªŒå·²åšè¿‡ï¼Œè¿™é‡Œç®€åŒ–)
            print("  ğŸ“Š åˆæˆæ•°æ®è®­ç»ƒ â†’ çœŸå®æ•°æ®æµ‹è¯•")
            model_s2r = build_model(
                model_name,
                F=metadata["F"],
                num_classes=metadata["num_classes"],
                T=metadata["T"]
            )
            
            model_s2r = model_s2r.to(device)
            optimizer = torch.optim.Adam(model_s2r.parameters(), lr=0.001)
            
            # åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒ
            for epoch in range(15):
                train_loss = train_one_epoch(model_s2r, synth_train_loader, optimizer, criterion, device)
            
            # åœ¨åˆæˆæ•°æ®æµ‹è¯•é›†ä¸Šè¯„ä¼° (å†…åŸŸ)
            synth_synth_results = eval_model(model_s2r, synth_test_loader, device)
            
            # åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯• (è·¨åŸŸ)  
            synth_real_results = eval_model(model_s2r, real_test_loader, device)
            
            # è®¡ç®—åŸŸå·®è·æŒ‡æ ‡
            results = {
                "real_to_real": real_real_results["macro_f1"],     # çœŸå®å†…åŸŸåŸºå‡†
                "real_to_synthetic": real_synth_results["macro_f1"], # çœŸå®â†’åˆæˆ
                "synthetic_to_synthetic": synth_synth_results["macro_f1"], # åˆæˆå†…åŸŸåŸºå‡†
                "synthetic_to_real": synth_real_results["macro_f1"],      # åˆæˆâ†’çœŸå®
                
                # åŸŸå·®è·æŒ‡æ ‡
                "real2synth_gap": 1 - (real_synth_results["macro_f1"] / max(real_real_results["macro_f1"], 0.001)),
                "synth2real_gap": 1 - (synth_real_results["macro_f1"] / max(synth_synth_results["macro_f1"], 0.001)),
                
                # å¯¹ç§°æ€§åˆ†æ
                "domain_asymmetry": abs(
                    (real_synth_results["macro_f1"] / max(real_real_results["macro_f1"], 0.001)) -
                    (synth_real_results["macro_f1"] / max(synth_synth_results["macro_f1"], 0.001))
                )
            }
            
            # ä¿å­˜ç»“æœ
            result_file = self.output_dir / f"domain_gap_{dataset_name}.json"
            with open(result_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"âœ… åŸŸå·®è·åˆ†æç»“æœå·²ä¿å­˜: {result_file}")
            print(f"  åˆæˆâ†’çœŸå®å·®è·: {results['synth2real_gap']:.3f}")
            print(f"  çœŸå®â†’åˆæˆå·®è·: {results['real2synth_gap']:.3f}")
            
            return results
            
        except Exception as e:
            print(f"âŒ å®éªŒ4å¤±è´¥: {e}")
            return {}
    
    def run_all_experiments(self, datasets=["UT_HAR"]):
        """è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å®éªŒ"""
        print("ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰ä¼˜åŒ–Sim2Realå®éªŒ")
        
        all_results = {}
        
        for dataset in datasets:
            print(f"\n{'='*50}")
            print(f"ğŸ¯ æ•°æ®é›†: {dataset}")
            print(f"{'='*50}")
            
            all_results[dataset] = {}
            
            # è¿è¡Œå„ä¸ªå®éªŒ (æŒ‰éœ€æ‰§è¡Œ)
            try:
                # all_results[dataset]["baseline"] = self.experiment_1_baseline_establishment(dataset)
                all_results[dataset]["sim2real_core"] = self.experiment_2_sim2real_core(dataset) 
                all_results[dataset]["few_shot"] = self.experiment_3_few_shot_learning(dataset)
                # all_results[dataset]["domain_gap"] = self.experiment_4_domain_gap_analysis(dataset)
                
            except Exception as e:
                print(f"âŒ æ•°æ®é›† {dataset} å®éªŒå¤±è´¥: {e}")
                print("å¯èƒ½åŸå› : æ•°æ®é›†æœªä¸‹è½½æˆ–ç¯å¢ƒé—®é¢˜")
                continue
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_file = self.output_dir / "all_experiments_summary.json"
        with open(summary_file, 'w') as f:
            json.dump(all_results, f, indent=2)
        
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ! ç»“æœæ±‡æ€»: {summary_file}")
        
        # ç”Ÿæˆç®€è¦æŠ¥å‘Š
        self.generate_summary_report(all_results)
        
        return all_results
    
    def generate_summary_report(self, results):
        """ç”Ÿæˆå®éªŒæ€»ç»“æŠ¥å‘Š"""
        report = []
        report.append("# ğŸ“Š Sim2Realå®éªŒæ€»ç»“æŠ¥å‘Š\n")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        for dataset, exp_results in results.items():
            if not exp_results:
                continue
                
            report.append(f"## ğŸ¯ æ•°æ®é›†: {dataset}\n")
            
            # Sim2Realæ ¸å¿ƒç»“æœ
            if "sim2real_core" in exp_results and exp_results["sim2real_core"]:
                report.append("### Sim2Realæ ¸å¿ƒç»“æœ")
                for model, metrics in exp_results["sim2real_core"].items():
                    ratio = metrics.get("sim2real_ratio", 0)
                    real_f1 = metrics.get("real_f1", 0)
                    report.append(f"- **{model}**: çœŸå®F1={real_f1:.3f}, Sim2Realæ¯”ç‡={ratio:.3f}")
                report.append("")
            
            # å°‘æ ·æœ¬å­¦ä¹ ç»“æœ
            if "few_shot" in exp_results and exp_results["few_shot"]:
                report.append("### å°‘æ ·æœ¬å­¦ä¹ æ•ˆç‡")
                for model, ratios in exp_results["few_shot"].items():
                    report.append(f"- **{model}**:")
                    for ratio, metrics in ratios.items():
                        f1 = metrics.get("macro_f1", 0)
                        samples = metrics.get("sample_count", 0)
                        report.append(f"  - {ratio}: F1={f1:.3f} ({samples}æ ·æœ¬)")
                report.append("")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.output_dir / "experiment_summary_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print(f"ğŸ“ å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸš€ ä¼˜åŒ–Sim2Realå®éªŒ")
    
    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiments = OptimizedSim2RealExperiments()
    
    # è¿è¡Œæ ¸å¿ƒå®éªŒ (æ ¹æ®æ•°æ®é›†å¯ç”¨æ€§è°ƒæ•´)
    try:
        # åªæµ‹è¯•å¯ç”¨çš„æ•°æ®é›†
        available_datasets = ["UT_HAR"]  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        
        results = experiments.run_all_experiments(available_datasets)
        
        if results:
            print("\nğŸ‰ å®éªŒå®Œæˆ!")
            print("å…³é”®å‘ç°:")
            for dataset, exp_results in results.items():
                if "sim2real_core" in exp_results:
                    for model, metrics in exp_results["sim2real_core"].items():
                        ratio = metrics.get("sim2real_ratio", 0)
                        print(f"- {model}åœ¨{dataset}: Sim2Realæ¯”ç‡={ratio:.3f}")
        
    except Exception as e:
        print(f"âŒ å®éªŒè¿è¡Œå¤±è´¥: {e}")
        print("è¿™æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœè¿˜æ²¡æœ‰ä¸‹è½½çœŸå®æ•°æ®é›†çš„è¯")
        print("\nğŸ“ å®éªŒè®¾è®¡å·²å®Œæˆï¼Œä»£ç æ¡†æ¶å·²å°±ç»ª!")
        print("ä¸‹ä¸€æ­¥: ä¸‹è½½æ•°æ®é›†å¹¶è¿è¡Œå®éªŒ")