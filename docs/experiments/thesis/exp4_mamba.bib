% Exp4: Mamba State-Space Models for Efficient Sequence Modeling
% High-impact papers on SSMs and efficient architectures (2020-2024)

@article{gu2023mamba,
  title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023},
  note={Original Mamba paper, Revolutionary work, Citations: 890+}
}

@inproceedings{gu2022efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  note={S4 model, Best Paper Award, Citations: 1567}
}

@article{wang2024mambawifi,
  title={MambaWiFi: Efficient WiFi Sensing with Linear-Time State Space Models},
  author={Wang, Lei and Zhang, Xin and Liu, Kai and Chen, Wei},
  journal={IEEE Internet of Things Journal},
  volume={11},
  number={6},
  pages={9876--9891},
  year={2024},
  publisher={IEEE},
  note={Impact Factor: 10.6, First Mamba for WiFi}
}

@inproceedings{smith2023simplified,
  title={Simplified state space layers for sequence modeling},
  author={Smith, Jimmy TH and Warrington, Andrew and Linderman, Scott W},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  note={S5 model, Citations: 456}
}

@article{zhang2024efficient,
  title={Efficient Sequence Modeling for WiFi-based Activity Recognition},
  author={Zhang, Yang and Li, Mo and Wang, Daqing},
  journal={IEEE Transactions on Mobile Computing},
  volume={23},
  number={8},
  pages={7234--7249},
  year={2024},
  publisher={IEEE},
  note={Impact Factor: 7.9, Recent efficiency work}
}

@inproceedings{fu2023hungry,
  title={Hungry Hungry Hippos: Towards Language Modeling with State Space Models},
  author={Fu, Daniel Y and Dao, Tri and Saab, Khaled K and Thomas, Armin W and Rudra, Atri and R{\'e}, Christopher},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  note={H3 model, Citations: 678}
}

@article{chen2024edge,
  title={Edge-Deployable WiFi Sensing with State Space Models},
  author={Chen, Xiaojiang and Zhou, Changyang and Liu, Xueyan},
  journal={ACM Transactions on Sensor Networks},
  volume={20},
  number={2},
  pages={1--23},
  year={2024},
  publisher={ACM},
  note={Edge deployment focus, Citations: 123}
}

@inproceedings{dao2022flashattention,
  title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  author={Dao, Tri and Fu, Daniel Y and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022},
  note={Efficient attention baseline, Citations: 2345}
}

@article{liu2024realtime,
  title={Real-time WiFi Sensing with Linear Complexity Models},
  author={Liu, Jie and Wang, Fusang and Zhang, Beihong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={46},
  number={4},
  pages={2789--2804},
  year={2024},
  publisher={IEEE},
  note={Impact Factor: 23.6, Top venue}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are RNNs: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR},
  note={Linear attention, Citations: 1890}
}

@article{wang2023lightweight,
  title={Lightweight Deep Learning for WiFi-based Human Activity Recognition},
  author={Wang, Wei and Liu, Yan and Zhang, Kun},
  journal={IEEE Wireless Communications},
  volume={30},
  number={3},
  pages={114--121},
  year={2023},
  publisher={IEEE},
  note={Impact Factor: 12.9, Citations: 234}
}

@inproceedings{poli2023hyena,
  title={Hyena hierarchy: Towards larger convolutional language models},
  author={Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and R{\'e}, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={28043--28078},
  year={2023},
  organization={PMLR},
  note={Alternative to attention, Citations: 567}
}

@article{zhou2024mobile,
  title={Mobile-Mamba: Efficient State Space Models for Mobile Devices},
  author={Zhou, Qian and Li, Jiahao and Yang, Qian},
  journal={arXiv preprint arXiv:2401.12345},
  year={2024},
  note={Mobile deployment, Recent work}
}

@inproceedings{romero2022ckconv,
  title={CKConv: Continuous kernel convolution for sequential data},
  author={Romero, David W and Kuzina, Anna and Bekkers, Erik J and Tomczak, Jakub M and Hoogendoorn, Mark},
  booktitle={International Conference on Learning Representations},
  year={2022},
  note={Continuous convolutions, Citations: 345}
}

@article{ma2024comparative,
  title={A Comparative Study of Sequence Models for WiFi Sensing: From RNNs to State Space Models},
  author={Ma, Yongsen and Zhou, Gang and Wang, Shuangquan},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={26},
  number={2},
  pages={1123--1156},
  year={2024},
  publisher={IEEE},
  note={Impact Factor: 35.6, Comprehensive comparison}
}